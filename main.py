import os
import time
import tempfile
import pyzipper
import logging
import sys
import asyncio
import aiohttp
import aiofiles
from pyrogram import Client, filters, enums
from pyrogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton
from pyrogram.errors import FloodWait, RPCError, SessionPasswordNeeded
from flask import Flask
import threading
from collections import deque
import random
import math
from typing import Dict, List, Callable, Any, Tuple, Optional
from pathlib import Path
import json
from datetime import datetime
import shutil
from concurrent.futures import ThreadPoolExecutor, as_completed
import queue

# ===== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ =====
class Config:
    API_ID = 26180086
    API_HASH = "d91e174c7faf0e5a6a3a2ecb0b3361f6"
    SESSION_STRING = "BAGPefYAEAaXaj52wzDLPF0RSfWtF_Slk8nFWzYAHS9vu-HBxRUz9yLnq7m8z-ajYCQxQZO-5aNX0he9OttDjmjieYDMbDjBJtbsOT2ZwsQNe8UCAo5oFPveD5V1H0cIBMlXCG1P49G2oonf1YL1r16Nt34AJLkmzDIoFD0hhxwVBXvrUGwZmEoTtdkfORCYUMGACKO4-Al-NH35oVCkTIqmXQ5DUp9PVx6DND243VW5Xcqay7qwrwfoS4sWRA-7TMXykbHa37ZsdcCOf0VS8e6PyaYvG5BjMCd9BGRnR9IImrksYY2uBM2Bg42MLaa1WFxQtn97p5ViPF9c1MpY49bc5Gm5lwAAAAF--TK5AA"
    ALLOWED_USER_IDS = [417536686]
    MAX_FILE_SIZE = 2147483648  # 2GB
    MAX_TOTAL_SIZE = 8589934592  # 8GB
    PART_SIZE = 1900 * 1024 * 1024  # 1900MB
    CHUNK_SIZE = 1 * 1024 * 1024  # 1MB Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ØªØ± Ø­Ø§ÙØ¸Ù‡
    MAX_CONCURRENT_DOWNLOADS = 2
    MAX_CONCURRENT_UPLOADS = 1
    RETRY_DELAY = 10
    PROGRESS_UPDATE_INTERVAL = 0.5
    DATA_FILE = "user_data.json"
    UPLOAD_CHUNK_SIZE = 4 * 1024 * 1024  # 4MB Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯
    MAX_UPLOAD_RETRIES = 5
    ZIP_COMPRESSION_LEVEL = 6  # Ø³Ø·Ø­ ÙØ´Ø±Ø¯Ù‡ Ø³Ø§Ø²ÛŒ (1-9)
    MAX_ZIP_RETRIES = 3  # Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡ Ø³Ø§Ø²ÛŒ
    ZIP_BASE_TIMEOUT = 3600  # 1 hour base timeout
    ZIP_TIMEOUT_PER_GB = 1800  # 30 minutes per additional GB

# ===== Ù„Ø§Ú¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("bot.log", encoding="utf-8")
    ]
)
logger = logging.getLogger(__name__)

# ===== Ú©Ù„Ø§ÛŒÙ†Øª Pyrogram =====
app = None

# ===== Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ ÙˆØ¶Ø¹ÛŒØª =====
user_files: Dict[int, List] = {}
user_states: Dict[int, Any] = {}
scheduled_tasks: List[Tuple[float, Callable, Tuple, Dict]] = []
task_queue = deque()
processing = False
download_semaphore = asyncio.Semaphore(Config.MAX_CONCURRENT_DOWNLOADS)
upload_semaphore = asyncio.Semaphore(Config.MAX_CONCURRENT_UPLOADS)
zip_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="ZipWorker")

# ===== Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ´Ø±ÙØª =====
class ProgressTracker:
    def __init__(self):
        self.start_time = time.time()
        self.last_update = 0
        self.last_text = ""
        self.last_percent = 0
        self.current = 0
        self.total = 0
        self.stage = ""
        self.file_name = ""
        self.message = None
        self.file_index = 0
        self.total_files = 0
        self.lock = asyncio.Lock()
        self.zip_progress_queue = queue.Queue()

    def reset(self, message: Message = None, stage: str = "", file_name: str = "", file_index: int = 0, total_files: int = 0):
        self.start_time = time.time()
        self.last_update = 0
        self.last_text = ""
        self.last_percent = 0
        self.current = 0
        self.total = 0
        self.stage = stage
        self.file_name = file_name
        self.message = message
        self.file_index = file_index
        self.total_files = total_files

    async def update(self, current: int, total: int):
        try:
            async with self.lock:
                now = time.time()
                if now - self.last_update < Config.PROGRESS_UPDATE_INTERVAL and current != total:
                    return
                
                self.current = current
                self.total = total
                self.last_update = now
                
                percent = (current / total) * 100 if total > 0 else 0
                elapsed = now - self.start_time
                speed = current / elapsed if elapsed > 0 else 0
                eta = (total - current) / speed if speed > 0 and current > 0 else 0
                
                if abs(percent - self.last_percent) < 0.5 and current != total:
                    return
                
                self.last_percent = percent
                
                bar = self.get_progress_bar(percent)
                
                if self.total_files > 1:
                    progress_text = (
                        f"ğŸš€ **{self.stage} ÙØ§ÛŒÙ„ {self.file_index}/{self.total_files}**\n\n"
                        f"{bar}\n\n"
                        f"ğŸ“ ÙØ§ÛŒÙ„: `{self.file_name[:30]}{'...' if len(self.file_name) > 30 else ''}`\n"
                        f"ğŸ“Š Ù¾ÛŒØ´Ø±ÙØª: `{self.format_size(current)} / {self.format_size(total)}`\n"
                        f"âš¡ Ø³Ø±Ø¹Øª: `{self.format_size(speed)}/s`\n"
                        f"â° Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: `{self.format_time(int(eta))}`\n"
                        f"ğŸ• Ø²Ù…Ø§Ù† Ø³Ù¾Ø±ÛŒ Ø´Ø¯Ù‡: `{self.format_time(int(elapsed))}`"
                    )
                else:
                    progress_text = (
                        f"ğŸš€ **{self.stage}**\n\n"
                        f"{bar}\n\n"
                        f"ğŸ“ ÙØ§ÛŒÙ„: `{self.file_name[:30]}{'...' if len(self.file_name) > 30 else ''}`\n"
                        f"ğŸ“Š Ù¾ÛŒØ´Ø±ÙØª: `{self.format_size(current)} / {self.format_size(total)}`\n"
                        f"âš¡ Ø³Ø±Ø¹Øª: `{self.format_size(speed)}/s`\n"
                        f"â° Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: `{self.format_time(int(eta))}`\n"
                        f"ğŸ• Ø²Ù…Ø§Ù† Ø³Ù¾Ø±ÛŒ Ø´Ø¯Ù‡: `{self.format_time(int(elapsed))}`"
                    )
                
                if self.last_text != progress_text and self.message:
                    try:
                        await self.message.edit_text(progress_text, parse_mode=enums.ParseMode.MARKDOWN)
                        self.last_text = progress_text
                    except Exception as e:
                        logger.error(f"Error updating progress: {e}")
                        
        except Exception as e:
            logger.error(f"Progress update error: {e}")

    async def update_zip_progress(self):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        try:
            while True:
                try:
                    current, total = self.zip_progress_queue.get_nowait()
                    await self.update(current, total)
                except queue.Empty:
                    await asyncio.sleep(0.1)
        except Exception as e:
            logger.error(f"Zip progress update error: {e}")

    @staticmethod
    def get_progress_bar(percentage: float, length: int = 20) -> str:
        filled = int(length * percentage / 100)
        bar = "â¬¢" * filled + "â¬¡" * (length - filled)
        return f"{bar} {percentage:.1f}%"

    @staticmethod
    def format_size(size_bytes: int) -> str:
        if size_bytes == 0:
            return "0B"
        size_names = ["B", "KB", "MB", "GB", "TB"]
        i = int(math.floor(math.log(size_bytes, 1024)))
        p = math.pow(1024, i)
        s = round(size_bytes / p, 2)
        return f"{s} {size_names[i]}"

    @staticmethod
    def format_time(seconds: int) -> str:
        if seconds < 60:
            return f"{seconds} Ø«Ø§Ù†ÛŒÙ‡"
        elif seconds < 3600:
            return f"{seconds // 60} Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ {seconds % 60} Ø«Ø§Ù†ÛŒÙ‡"
        else:
            return f"{seconds // 3600} Ø³Ø§Ø¹Øª Ùˆ {(seconds % 3600) // 60} Ø¯Ù‚ÛŒÙ‚Ù‡"

# Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ù¾ÛŒØ´Ø±ÙØª
progress_tracker = ProgressTracker()

# ===== ÙØ§Ù†Ú©Ø´Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ =====
def is_user_allowed(user_id: int) -> bool:
    return user_id in Config.ALLOWED_USER_IDS

def load_user_data():
    global user_files, user_states
    try:
        if os.path.exists(Config.DATA_FILE):
            with open(Config.DATA_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                user_files = {int(k): v for k, v in data.get('user_files', {}).items()}
                user_states = {int(k): v for k, v in data.get('user_states', {}).items()}
                logger.info("User data loaded successfully")
    except Exception as e:
        logger.error(f"Error loading user data: {e}")

def save_user_data():
    try:
        data = {
            'user_files': user_files,
            'user_states': user_states
        }
        with open(Config.DATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Error saving user data: {e}")

async def safe_send_message(chat_id, text, reply_to_message_id=None, reply_markup=None, parse_mode=None):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            await asyncio.sleep(random.uniform(1.0, 3.0))
            return await app.send_message(
                chat_id, 
                text, 
                reply_to_message_id=reply_to_message_id,
                reply_markup=reply_markup,
                parse_mode=parse_mode
            )
        except FloodWait as e:
            wait_time = e.value + random.uniform(2, 5)
            logger.warning(f"FloodWait: {wait_time} seconds (attempt {attempt + 1}/{max_retries})")
            await asyncio.sleep(wait_time)
        except Exception as e:
            logger.error(f"Error sending message (attempt {attempt + 1}): {e}")
            await asyncio.sleep(2)
    
    try:
        return await app.send_message(
            chat_id, 
            text, 
            reply_to_message_id=reply_to_message_id,
            reply_markup=reply_markup
        )
    except Exception as e:
        logger.error(f"Failed to send message even without parse_mode: {e}")
        return None

async def safe_download_media(message, file_path, file_name="", file_index=0, total_files=0, processing_msg=None):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            async with download_semaphore:
                await asyncio.sleep(random.uniform(1.0, 3.0))
                
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                
                progress_tracker.reset(processing_msg, "Ø¯Ø§Ù†Ù„ÙˆØ¯", file_name, file_index, total_files)
                
                await app.download_media(
                    message,
                    file_name=file_path,
                    progress=progress_tracker.update
                )
                
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    return True
                else:
                    logger.warning(f"Downloaded file is empty or missing (attempt {attempt + 1})")
                    
        except FloodWait as e:
            wait_time = e.value + random.uniform(5, 10)
            logger.warning(f"Download FloodWait: {wait_time} seconds (attempt {attempt + 1})")
            await asyncio.sleep(wait_time)
        except (RPCError, aiohttp.ClientError, OSError) as e:
            logger.error(f"Download error (attempt {attempt + 1}): {e}")
            await asyncio.sleep(Config.RETRY_DELAY)
        except Exception as e:
            logger.error(f"Unexpected download error (attempt {attempt + 1}): {e}")
            await asyncio.sleep(Config.RETRY_DELAY)
    
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
    except:
        pass
    
    return False

def schedule_task(task_func: Callable, delay: float, *args, **kwargs):
    execution_time = time.time() + delay
    scheduled_tasks.append((execution_time, task_func, args, kwargs))
    scheduled_tasks.sort(key=lambda x: x[0])

async def process_scheduled_tasks():
    while True:
        now = time.time()
        tasks_to_run = []
        
        for i, (execution_time, task_func, args, kwargs) in enumerate(scheduled_tasks):
            if execution_time <= now:
                tasks_to_run.append((task_func, args, kwargs))
                scheduled_tasks.pop(i)
            else:
                break
        
        for task_func, args, kwargs in tasks_to_run:
            try:
                if asyncio.iscoroutinefunction(task_func):
                    await task_func(*args, **kwargs)
                else:
                    await asyncio.to_thread(task_func, *args, **kwargs)
            except Exception as e:
                logger.error(f"Scheduled task error: {e}")
        
        await asyncio.sleep(1)

async def process_task_queue():
    global processing
    
    while True:
        if not task_queue:
            await asyncio.sleep(1)
            continue
        
        processing = True
        task_func, args, kwargs = task_queue.popleft()
        
        try:
            if asyncio.iscoroutinefunction(task_func):
                await task_func(*args, **kwargs)
            else:
                await asyncio.to_thread(task_func, *args, **kwargs)
            
            await asyncio.sleep(random.uniform(2.0, 5.0))
            
        except FloodWait as e:
            wait_time = e.value + random.uniform(10, 15)
            logger.warning(f"ğŸ•’ FloodWait detected: {wait_time} seconds. Rescheduling task...")
            
            schedule_task(task_func, wait_time, *args, **kwargs)
            
            user_id = kwargs.get('user_id', args[0] if args else None)
            if user_id:
                await notify_user_floodwait(user_id, wait_time)
            
            await asyncio.sleep(5)
            
        except Exception as e:
            logger.error(f"Task error: {e}")
            await asyncio.sleep(5)
        
        finally:
            processing = False
            save_user_data()

def add_to_queue(task_func: Callable, *args, **kwargs):
    task_queue.append((task_func, args, kwargs))
    logger.info(f"Task added to queue. Queue size: {len(task_queue)}")

async def notify_user_floodwait(user_id: int, wait_time: int):
    try:
        wait_minutes = wait_time // 60
        wait_seconds = wait_time % 60
        
        await safe_send_message(
            user_id,
            f"â³ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù…ÙˆÙ‚Øª ØªÙ„Ú¯Ø±Ø§Ù…ØŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯.\n"
            f"ğŸ•’ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±: {wait_minutes} Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ {wait_seconds} Ø«Ø§Ù†ÛŒÙ‡\n"
            f"âœ… Ø¨Ø¹Ø¯ Ø§Ø² Ø§ÛŒÙ† Ø²Ù…Ø§Ù†ØŒ Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯."
        )
    except Exception as e:
        logger.error(f"Error notifying user about floodwait: {e}")

def calculate_zip_timeout(total_size_mb: float) -> int:
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ timeout Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø¬Ù… ÙØ§ÛŒÙ„"""
    base_timeout = Config.ZIP_BASE_TIMEOUT
    additional_time = max(0, (total_size_mb - 1024) / 1024 * Config.ZIP_TIMEOUT_PER_GB)
    total_timeout = min(base_timeout + additional_time, 6 * 3600)  # Ø­Ø¯Ø§Ú©Ø«Ø± 6 Ø³Ø§Ø¹Øª
    logger.info(f"Calculated zip timeout: {total_timeout/60:.1f} minutes for {total_size_mb:.1f}MB")
    return int(total_timeout)

def zip_creation_task(zip_path: str, files: List[Dict], password: Optional[str], progress_queue: queue.Queue) -> bool:
    """ØªØ§Ø¨Ø¹ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ù¾ÛŒØ´Ø±ÙØª"""
    try:
        total_size = sum(f['size'] for f in files)
        processed_size = 0
        
        logger.info(f"Starting zip creation for {len(files)} files, total size: {total_size/1024/1024:.1f}MB")
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        for file_info in files:
            if not os.path.exists(file_info['path']):
                logger.error(f"File not found: {file_info['path']}")
                return False
            if os.path.getsize(file_info['path']) == 0:
                logger.error(f"File is empty: {file_info['path']}")
                return False
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§Ù„Øª Ø¨Ø¯ÙˆÙ† ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù‚Ø¨Ù„ ÙØ´Ø±Ø¯Ù‡
        compression = pyzipper.ZIP_STORED if any(f['name'].lower().endswith(('.zip', '.rar', '.7z', '.tar', '.gz')) for f in files) else pyzipper.ZIP_DEFLATED
        
        with pyzipper.AESZipFile(
            zip_path, 
            "w", 
            compression=compression,
            compresslevel=Config.ZIP_COMPRESSION_LEVEL,
            encryption=pyzipper.WZ_AES if password else None,
            allowZip64=True
        ) as zipf:
            
            if password:
                try:
                    zipf.setpassword(password.encode('utf-8'))
                    logger.info("Password set successfully")
                except Exception as e:
                    logger.error(f"Error setting password: {e}")
                    return False
            
            for file_info in files:
                file_path = file_info['path']
                arcname = os.path.basename(file_info['name'])
                
                if not os.path.exists(file_path):
                    logger.error(f"File disappeared during processing: {file_path}")
                    continue
                
                try:
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø¨Ù‡ Ø²ÛŒÙ¾
                    zipf.write(file_path, arcname)
                    processed_size += file_info['size']
                    
                    # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ´Ø±ÙØª Ø¨Ù‡ ØµÙ
                    progress_queue.put((processed_size, total_size))
                    logger.debug(f"Added {arcname} to zip, progress: {processed_size}/{total_size}")
                    
                except Exception as e:
                    logger.error(f"Error adding file {arcname} to zip: {e}")
                    continue
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾
        if os.path.exists(zip_path) and os.path.getsize(zip_path) > 0:
            zip_size = os.path.getsize(zip_path)
            compression_ratio = (1 - (zip_size / total_size)) * 100 if total_size > 0 else 0
            logger.info(f"Zip created successfully: {zip_path}, "
                       f"size: {zip_size/1024/1024:.1f}MB, "
                       f"compression: {compression_ratio:.1f}%")
            
            # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø³Ø§Ø¯Ù‡
            try:
                with pyzipper.AESZipFile(zip_path, 'r') as test_zip:
                    if password:
                        test_zip.setpassword(password.encode('utf-8'))
                    # ÙÙ‚Ø· Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ ÙØ§ÛŒÙ„ Ù‚Ø§Ø¨Ù„ Ø¨Ø§Ø² Ø´Ø¯Ù† Ø¨Ø§Ø´Ø¯
                    test_zip.testzip()
                    logger.info("Zip validation passed")
                    return True
            except Exception as test_error:
                logger.error(f"Zip validation failed: {test_error}")
                return False
        else:
            logger.error("Created zip file is empty or missing")
            return False
            
    except Exception as e:
        logger.error(f"Error in zip creation: {e}", exc_info=True)
        # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ø®Ø±Ø§Ø¨
        try:
            if os.path.exists(zip_path):
                os.remove(zip_path)
        except:
            pass
        return False

async def create_zip_part_advanced(zip_path: str, files: List[Dict], default_password: Optional[str] = None) -> bool:
    """ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÙØ´Ø±Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ Ùˆ timeout"""
    max_retries = Config.MAX_ZIP_RETRIES
    
    for attempt in range(max_retries):
        try:
            # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ù…Ù‚ØµØ¯
            os.makedirs(os.path.dirname(zip_path), exist_ok=True)
            
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
            if os.path.exists(zip_path):
                try:
                    os.remove(zip_path)
                    logger.info(f"Removed existing zip file: {zip_path}")
                except Exception as e:
                    logger.error(f"Error removing existing zip: {e}")
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹
            missing_files = []
            empty_files = []
            for file_info in files:
                if not os.path.exists(file_info['path']):
                    missing_files.append(file_info['name'])
                    logger.error(f"File not found: {file_info['path']}")
                elif os.path.getsize(file_info['path']) == 0:
                    empty_files.append(file_info['name'])
                    logger.error(f"File is empty: {file_info['path']}")
            
            if missing_files or empty_files:
                logger.error(f"Problematic files - Missing: {missing_files}, Empty: {empty_files}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(5)
                    continue
                else:
                    return False
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ timeout Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø¬Ù…
            total_size_mb = sum(f['size'] for f in files) / (1024 * 1024)
            dynamic_timeout = calculate_zip_timeout(total_size_mb)
            
            logger.info(f"Zip attempt {attempt + 1}/{max_retries} for {len(files)} files, "
                       f"total: {total_size_mb:.1f}MB, timeout: {dynamic_timeout/60:.1f}min")
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ThreadPoolExecutor Ø¨Ø±Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø¯Ø± background
            loop = asyncio.get_event_loop()
            
            # Ø§Ø¬Ø±Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø¨Ø§ timeout
            success = await asyncio.wait_for(
                loop.run_in_executor(
                    zip_executor, 
                    zip_creation_task, 
                    zip_path, files, default_password, progress_tracker.zip_progress_queue
                ),
                timeout=dynamic_timeout
            )
            
            if success:
                # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾
                if os.path.exists(zip_path) and os.path.getsize(zip_path) > 0:
                    logger.info(f"Zip part created successfully: {zip_path}, "
                               f"size: {os.path.getsize(zip_path)/1024/1024:.1f}MB")
                    return True
                else:
                    logger.error("Zip file created but is empty or missing")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(3)
                        continue
            
        except asyncio.TimeoutError:
            logger.error(f"Zip creation timeout (attempt {attempt + 1}/{max_retries})")
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù†Ø§ØªÙ…Ø§Ù…
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
                    logger.info("Removed timeout zip file")
            except Exception as e:
                logger.error(f"Error removing timeout zip file: {e}")
            
            if attempt < max_retries - 1:
                retry_delay = random.uniform(10, 20)
                logger.info(f"Retrying after timeout in {retry_delay:.1f} seconds...")
                await asyncio.sleep(retry_delay)
                
        except Exception as e:
            logger.error(f"Unexpected error in zip creation (attempt {attempt + 1}/{max_retries}): {e}", exc_info=True)
            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù†Ø§ØªÙ…Ø§Ù…
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
            except:
                pass
            
            if attempt < max_retries - 1:
                retry_delay = random.uniform(3, 10)
                logger.info(f"Retrying after error in {retry_delay:.1f} seconds...")
                await asyncio.sleep(retry_delay)
    
    logger.error(f"All {max_retries} zip attempts failed")
    return False

async def upload_large_file(file_path: str, chat_id: int, caption: str, reply_to_message_id: int, 
                           progress_callback, progress_args) -> bool:
    """Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø®Ø·Ø§"""
    max_retries = Config.MAX_UPLOAD_RETRIES
    
    for attempt in range(max_retries):
        try:
            async with upload_semaphore:
                if attempt > 0:
                    wait_time = random.uniform(10, 30)
                    logger.info(f"Upload retry {attempt + 1}/{max_retries} after {wait_time:.1f} seconds")
                    await asyncio.sleep(wait_time)
                
                await app.send_document(
                    chat_id=chat_id,
                    document=file_path,
                    caption=caption,
                    reply_to_message_id=reply_to_message_id,
                    progress=progress_callback,
                    progress_args=progress_args,
                    chunk_size=Config.UPLOAD_CHUNK_SIZE
                )
                
                logger.info(f"File uploaded successfully: {file_path}")
                return True
                
        except FloodWait as e:
            wait_time = e.value + random.uniform(5, 15)
            logger.warning(f"Upload FloodWait: {wait_time} seconds (attempt {attempt + 1}/{max_retries})")
            
            if attempt == max_retries - 1:
                logger.error(f"Max retries reached for upload: {file_path}")
                return False
                
            await asyncio.sleep(wait_time)
            
        except RPCError as e:
            logger.error(f"RPCError during upload (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return False
            await asyncio.sleep(Config.RETRY_DELAY)
            
        except OSError as e:
            logger.error(f"OSError during upload (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return False
            await asyncio.sleep(Config.RETRY_DELAY)
            
        except Exception as e:
            logger.error(f"Unexpected error during upload (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return False
            await asyncio.sleep(Config.RETRY_DELAY)
    
    return False

async def upload_zip_part(zip_path: str, part_number: int, total_parts: int, 
                         chat_id: int, message_id: int, password: str, processing_msg: Message):
    try:
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ù‚Ø¨Ù„ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯
        if not os.path.exists(zip_path) or os.path.getsize(zip_path) == 0:
            logger.error(f"Zip file not found or empty: {zip_path}")
            return False
            
        part_size = os.path.getsize(zip_path)
        
        progress_tracker.reset(processing_msg, "Ø¢Ù¾Ù„ÙˆØ¯", f"Ù¾Ø§Ø±Øª {part_number + 1}", part_number + 1, total_parts)
        
        caption = (
            f"ğŸ“¦ Ù¾Ø§Ø±Øª {part_number + 1}/{total_parts}\n"
            f"ğŸ”‘ Ø±Ù…Ø²: `{password}`\n"
            f"ğŸ’¾ Ø­Ø¬Ù…: {progress_tracker.format_size(part_size)}"
        )
        
        success = await upload_large_file(
            file_path=zip_path,
            chat_id=chat_id,
            caption=caption,
            reply_to_message_id=message_id,
            progress_callback=progress_tracker.update,
            progress_args=()
        )
        
        if success:
            logger.info(f"Part {part_number + 1}/{total_parts} uploaded successfully")
            await asyncio.sleep(random.uniform(3.0, 8.0))
            return True
        else:
            logger.error(f"Failed to upload part {part_number + 1}/{total_parts}")
            return False
            
    except FloodWait as e:
        wait_time = e.value + random.uniform(10, 20)
        logger.warning(f"Upload FloodWait in main function: {wait_time} seconds")
        
        schedule_task(
            upload_zip_part, 
            wait_time, 
            zip_path, part_number, total_parts, 
            chat_id, message_id, password, processing_msg
        )
        
        try:
            await processing_msg.edit_text(
                f"â³ **Ø¢Ù¾Ù„ÙˆØ¯ Ù…ØªÙˆÙ‚Ù Ø´Ø¯**\n\n"
                f"ğŸ“¦ Ù¾Ø§Ø±Øª: {part_number + 1}/{total_parts}\n"
                f"ğŸ•’ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¹Ø¯ Ø§Ø²: {wait_time:.0f} Ø«Ø§Ù†ÛŒÙ‡\n"
                f"âœ… Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø®ÙˆØ§Ù‡Ø¯ ÛŒØ§ÙØª",
                parse_mode=enums.ParseMode.MARKDOWN
            )
        except:
            pass
            
        return False
        
    except Exception as e:
        logger.error(f"Error uploading part {part_number}: {e}")
        return False

async def cleanup_files(file_paths: List[str]):
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª"""
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                if os.path.isdir(file_path):
                    shutil.rmtree(file_path)
                else:
                    os.remove(file_path)
                logger.info(f"Cleaned up file: {file_path}")
        except Exception as e:
            logger.error(f"Error cleaning up file {file_path}: {e}")

# ===== Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ =====
async def start(client, message: Message):
    if not is_user_allowed(message.from_user.id):
        return
    
    welcome_text = (
        "ğŸ‘‹ **Ø³Ù„Ø§Ù…! Ø¨Ù‡ Ø±Ø¨Ø§Øª Ø²ÛŒÙ¾ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯**\n\n"
        "âœ¨ **Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø±Ø¨Ø§Øª:**\n"
        "â€¢ ğŸ”’ Ø²ÛŒÙ¾ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ AES-256\n"
        "â€¢ ğŸ“¦ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø²ÛŒØ± 2GB\n"
        "â€¢ âš¡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ\n"
        "â€¢ ğŸ›¡ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…\n"
        "â€¢ ğŸ“Š Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ\n\n"
        "ğŸ“ **Ø±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡:**\n"
        "1. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
        "2. Ø§Ø² Ú©Ù¾Ø´Ù† `pass=Ø±Ù…Ø²` Ø¨Ø±Ø§ÛŒ Ø±Ù…Ø² Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù‡Ø± ÙØ§ÛŒÙ„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
        "3. Ø¯Ø³ØªÙˆØ± /zip Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\n\n"
        f"âš™ï¸ **Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§:**\n"
        f"â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± Ø­Ø¬Ù… Ù‡Ø± ÙØ§ÛŒÙ„: {progress_tracker.format_size(Config.MAX_FILE_SIZE)}\n"
        f"â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± Ø­Ø¬Ù… Ú©Ù„: {progress_tracker.format_size(Config.MAX_TOTAL_SIZE)}\n\n"
        "ğŸ›  Ø¨Ø±Ø§ÛŒ Ù„ØºÙˆ Ø¹Ù…Ù„ÛŒØ§Øª Ø§Ø² /cancel Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"
    )
    
    keyboard = InlineKeyboardMarkup([
        [InlineKeyboardButton("ğŸ“¦ Ø´Ø±ÙˆØ¹ Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„", callback_data="start_upload")],
        [InlineKeyboardButton("â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„", callback_data="help")]
    ])
    
    await safe_send_message(
        message.chat.id,
        welcome_text,
        reply_to_message_id=message.id,
        reply_markup=keyboard,
        parse_mode=enums.ParseMode.MARKDOWN
    )

async def handle_file(client, message: Message):
    if not is_user_allowed(message.from_user.id):
        return
    
    if not message.document and not message.video and not message.audio:
        return
    
    if message.document:
        file_obj = message.document
        file_type = "document"
    elif message.video:
        file_obj = message.video
        file_type = "video"
    elif message.audio:
        file_obj = message.audio
        file_type = "audio"
    else:
        return
    
    file_name = getattr(file_obj, 'file_name', None) or f"{file_type}_{message.id}"
    file_size = file_obj.file_size
    caption = message.caption or ""
    password = None
    
    if "pass=" in caption:
        password_match = caption.split("pass=", 1)[1].split()[0].strip()
        if password_match:
            password = password_match
    
    if file_size > Config.MAX_FILE_SIZE:
        await safe_send_message(
            message.chat.id,
            f"âŒ **Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø§Ø³Øª!**\n\n"
            f"ğŸ“¦ Ø­Ø¬Ù… ÙØ§ÛŒÙ„: {progress_tracker.format_size(file_size)}\n"
            f"âš–ï¸ Ø­Ø¯ Ù…Ø¬Ø§Ø²: {progress_tracker.format_size(Config.MAX_FILE_SIZE)}",
            reply_to_message_id=message.id
        )
        return
    
    user_id = message.from_user.id
    if user_id not in user_files:
        user_files[user_id] = []
    
    existing_files = [f['file_name'] for f in user_files[user_id]]
    if file_name in existing_files:
        base, ext = os.path.splitext(file_name)
        file_name = f"{base}_{message.id}{ext}"
    
    user_files[user_id].append({
        "message_id": message.id,
        "file_name": file_name, 
        "password": password, 
        "file_size": file_size,
        "file_type": file_type,
        "added_time": time.time()
    })
    
    total_size = sum(f["file_size"] for f in user_files[user_id])
    file_count = len(user_files[user_id])
    
    await safe_send_message(
        message.chat.id,
        f"âœ… **ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯**\n\n"
        f"ğŸ“ Ù†Ø§Ù…: `{file_name}`\n"
        f"ğŸ“¦ Ø­Ø¬Ù…: `{progress_tracker.format_size(file_size)}`\n"
        f"ğŸ”‘ Ø±Ù…Ø²: `{password if password else 'âŒ Ù†Ø¯Ø§Ø±Ø¯'}`\n\n"
        f"ğŸ“Š ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ: `{file_count}` ÙØ§ÛŒÙ„ (`{progress_tracker.format_size(total_size)}`)\n\n"
        f"ğŸ“Œ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø²ÛŒÙ¾ Ø§Ø² `/zip` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯",
        reply_to_message_id=message.id,
        parse_mode=enums.ParseMode.MARKDOWN
    )
    
    save_user_data()

async def start_zip(client, message: Message):
    if not is_user_allowed(message.from_user.id):
        return
    
    user_id = message.from_user.id
    if user_id not in user_files or not user_files[user_id]:
        await safe_send_message(
            message.chat.id,
            "âŒ **Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø²ÛŒÙ¾ Ú©Ø±Ø¯Ù† ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯**\n\n"
            "ğŸ“ Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯",
            reply_to_message_id=message.id
        )
        return
    
    total_size = sum(f["file_size"] for f in user_files[user_id])
    if total_size > Config.MAX_TOTAL_SIZE:
        await safe_send_message(
            message.chat.id,
            f"âŒ **Ø­Ø¬Ù… Ú©Ù„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø§Ø³Øª!**\n\n"
            f"ğŸ“¦ Ø­Ø¬Ù… Ú©Ù„: {progress_tracker.format_size(total_size)}\n"
            f"âš–ï¸ Ø­Ø¯ Ù…Ø¬Ø§Ø²: {progress_tracker.format_size(Config.MAX_TOTAL_SIZE)}\n\n"
            f"ğŸ“Œ Ù„Ø·ÙØ§Ù‹ ØªØ¹Ø¯Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯",
            reply_to_message_id=message.id
        )
        user_files[user_id] = []
        save_user_data()
        return
    
    user_states[user_id] = "waiting_password"
    
    await safe_send_message(
        message.chat.id,
        "ğŸ” **Ù„Ø·ÙØ§Ù‹ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:**\n\n"
        "ğŸ“ Ù¾Ø³ Ø§Ø² ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø±Ù…Ø²ØŒ Ø§Ø² /done Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
        "âš ï¸ ØªÙˆØ¬Ù‡: Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯",
        reply_to_message_id=message.id
    )

async def start_zip_now(client, message: Message):
    user_id = message.from_user.id
    
    if not is_user_allowed(user_id):
        return
    
    if user_states.get(user_id) != "ready_to_zip":
        await message.reply("âŒ Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ Ù…Ø±Ø§Ø­Ù„ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ú©Ø§Ù…Ù„ Ú©Ù†ÛŒØ¯")
        return
    
    zip_name = user_states.get(f"{user_id}_zipname", f"archive_{int(time.time())}")
    
    add_to_queue(process_zip_files, user_id, zip_name, message.chat.id, message.id)
    
    await message.reply("âœ… **Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø²ÛŒÙ¾ Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.**\n\nâ³ Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒØ´ÙˆØ¯...")

async def cancel_zip(client, message: Message):
    user_id = message.from_user.id
    if user_id in user_files:
        user_files[user_id] = []
    
    user_states.pop(user_id, None)
    user_states.pop(f"{user_id}_password", None)
    user_states.pop(f"{user_id}_zipname", None)
    
    save_user_data()
    
    await safe_send_message(
        message.chat.id,
        "âŒ **Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯**\n\n"
        "âœ… Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ù¾Ø§Ú© Ø´Ø¯Ù†Ø¯\n"
        "ğŸ“Œ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯",
        reply_to_message_id=message.id
    )

async def process_zip(client, message: Message):
    user_id = message.from_user.id
    
    if user_id not in user_states:
        return
    
    if user_states.get(user_id) == "waiting_password":
        zip_password = message.text.strip()
        
        if not zip_password:
            await message.reply("âŒ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯")
            return
        
        if len(zip_password) < 4:
            await message.reply("âŒ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯")
            return
        
        user_states[user_id] = "waiting_filename"
        user_states[f"{user_id}_password"] = zip_password
        
        suggested_name = f"archive_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        await message.reply(f"ğŸ“ **Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:**\n\nğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: `{suggested_name}`\n\nâœ… Ù¾Ø³ Ø§Ø² ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù†Ø§Ù…ØŒ Ø§Ø² /done Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
        return
    
    if user_states.get(user_id) == "waiting_filename":
        zip_name = message.text.strip()
        if not zip_name:
            await message.reply("âŒ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯")
            return
        
        import re
        zip_name = re.sub(r'[<>:"/\\|?*]', '_', zip_name)
        zip_name = zip_name[:50]
        
        user_states[f"{user_id}_zipname"] = zip_name
        user_states[user_id] = "ready_to_zip"
        
        total_files = len(user_files[user_id])
        total_size = sum(f["file_size"] for f in user_files[user_id])
        password = user_states.get(f"{user_id}_password", "Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø²")
        
        await message.reply(
            f"ğŸ“¦ **Ø®Ù„Ø§ØµÙ‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø²ÛŒÙ¾**\n\n"
            f"ğŸ“ Ù†Ø§Ù… ÙØ§ÛŒÙ„: `{zip_name}.zip`\n"
            f"ğŸ”‘ Ø±Ù…Ø²: `{password}`\n"
            f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: `{total_files}`\n"
            f"ğŸ’¾ Ø­Ø¬Ù… Ú©Ù„: `{progress_tracker.format_size(total_size)}`\n\n"
            f"âœ… Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø²ÛŒÙ¾ Ø§Ø² Ø¯Ø³ØªÙˆØ± `/zipnow` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
            f"âŒ Ø¨Ø±Ø§ÛŒ Ù„ØºÙˆ Ø§Ø² `/cancel` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯",
            parse_mode=enums.ParseMode.MARKDOWN
        )

async def handle_done_command(client, message: Message):
    user_id = message.from_user.id
    
    if user_id not in user_states:
        await message.reply("âŒ Ù‡ÛŒÚ† ÙØ±Ø¢ÛŒÙ†Ø¯ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ù†ÛŒØ³Øª")
        return
    
    if user_states.get(user_id) == "waiting_password":
        await message.reply("âŒ Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯")
        return
    
    if user_states.get(user_id) == "waiting_filename":
        await message.reply("âŒ Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯")
        return
    
    await message.reply("âœ… Ø¯Ø³ØªÙˆØ± /done Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")

async def handle_callback_query(client, callback_query):
    user_id = callback_query.from_user.id
    data = callback_query.data
    
    if not is_user_allowed(user_id):
        await callback_query.answer("Ø¯Ø³ØªØ±Ø³ÛŒ denied!", show_alert=True)
        return
    
    if data == "start_upload":
        await callback_query.answer()
        await safe_send_message(
            user_id,
            "ğŸ“¤ **Ø­Ø§Ù„Øª Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ ÙØ¹Ø§Ù„ Ø´Ø¯**\n\n"
            "ğŸ“ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
            "ğŸ”‘ Ø¨Ø±Ø§ÛŒ Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø² Ú©Ù¾Ø´Ù† `pass=Ø±Ù…Ø²` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
            "ğŸ“Œ Ù¾Ø³ Ø§Ø² Ø§ØªÙ…Ø§Ù… Ø§Ø² /zip Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯",
            parse_mode=enums.ParseMode.MARKDOWN
        )
    
    elif data == "help":
        await callback_query.answer()
        await safe_send_message(
            user_id,
            "ğŸ“– **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø±Ø¨Ø§Øª**\n\n"
            "1. Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø±Ø¨Ø§Øª Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
            "2. Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ: Ø¯Ø± Ú©Ù¾Ø´Ù† Ø§Ø² `pass=Ø±Ù…Ø²` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
            "3. Ø´Ø±ÙˆØ¹ Ø²ÛŒÙ¾: Ù¾Ø³ Ø§Ø² Ø§Ø±Ø³Ø§Ù„ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ØŒ /zip Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯\n"
            "4. ØªÙ†Ø¸ÛŒÙ…Ø§Øª: Ø±Ù…Ø² Ú©Ù„ÛŒ Ùˆ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\n"
            "5. Ø¯Ø±ÛŒØ§ÙØª: Ø±Ø¨Ø§Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø²ÛŒÙ¾ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\n\n"
            "âš™ï¸ **ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡:**\n"
            "â€¢ ØªÙ‚Ø³ÛŒÙ… Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± 2GB\n"
            "â€¢ Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ AES-256\n"
            "â€¢ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø² Ø®Ø·Ø§\n"
            "â€¢ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙ„Ú¯Ø±Ø§Ù…\n\n"
            "ğŸ›  Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ: Ø¯Ø± ØµÙˆØ±Øª Ù…Ø´Ú©Ù„ Ø¨Ø§ /cancel Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯",
            parse_mode=enums.ParseMode.MARKDOWN
        )
    
    elif data == "no_password":
        await callback_query.answer("Ø­Ø§Ù„Øª Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø² Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯")
        user_states[user_id] = "waiting_filename"
        user_states[f"{user_id}_password"] = None
        
        suggested_name = f"archive_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        await safe_send_message(
            user_id,
            f"ğŸ“ **Ø­Ø§Ù„Ø§ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯**\n\n"
            f"ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: {suggested_name}\n"
            f"âš ï¸ ØªÙˆØ¬Ù‡: Ù¾Ø³ÙˆÙ†Ø¯ .zip Ø§Ø¶Ø§ÙÙ‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯"
        )
    
    elif data == "confirm_zip":
        await callback_query.answer("Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø±ÙˆØ¹ Ø´Ø¯...")
        zip_name = user_states.get(f"{user_id}_zipname", f"archive_{int(time.time())}")
        add_to_queue(process_zip_files, user_id, zip_name, callback_query.message.chat.id, callback_query.message.id)
    
    elif data == "cancel_zip":
        await callback_query.answer("Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯")
        await cancel_zip(client, callback_query.message)
    
    await callback_query.message.delete()

def non_command_filter(_, __, message: Message):
    user_id = message.from_user.id
    return (message.text and 
            not message.text.startswith('/') and 
            user_id in user_states and
            user_states.get(user_id) in ["waiting_password", "waiting_filename"])

non_command = filters.create(non_command_filter)

async def process_zip_files(user_id, zip_name, chat_id, message_id):
    processing_msg = None
    temp_files_to_cleanup = []
    
    try:
        processing_msg = await app.send_message(chat_id, "â³ **Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ...**\n\nğŸŒ€ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯", parse_mode=enums.ParseMode.MARKDOWN)
        zip_password = user_states.get(f"{user_id}_password")
        
        # Ø´Ø±ÙˆØ¹ task Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ù¾ÛŒØ´Ø±ÙØª ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ
        zip_progress_task = asyncio.create_task(progress_tracker.update_zip_progress())
        
        with tempfile.TemporaryDirectory() as tmp_dir:
            total_files = len(user_files[user_id])
            file_info_list = []
            
            # Ù…Ø±Ø­Ù„Ù‡ 1: Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
            for i, finfo in enumerate(user_files[user_id], 1):
                file_msg_id = finfo["message_id"]
                
                try:
                    file_msg = await app.get_messages(chat_id, file_msg_id)
                    if not file_msg:
                        logger.error(f"Message {file_msg_id} not found")
                        continue
                    
                    file_name = finfo["file_name"]
                    file_path = os.path.join(tmp_dir, file_name)
                    temp_files_to_cleanup.append(file_path)
                    
                    success = await safe_download_media(
                        file_msg,
                        file_path,
                        file_name,
                        i,
                        total_files,
                        processing_msg
                    )
                    
                    if success and os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                        file_size = os.path.getsize(file_path)
                        file_info_list.append({
                            'path': file_path,
                            'name': file_name,
                            'size': file_size,
                            'password': finfo["password"] or zip_password
                        })
                        logger.info(f"Downloaded {file_name} ({progress_tracker.format_size(file_size)})")
                    else:
                        logger.error(f"Failed to download {file_name}")
                        # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ø®Ø±Ø§Ø¨
                        try:
                            if os.path.exists(file_path):
                                os.remove(file_path)
                        except:
                            pass
                    
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    logger.error(f"Error processing file {finfo['file_name']}: {e}")
                    continue
            
            if not file_info_list:
                await processing_msg.edit_text("âŒ **Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯**\n\nÙ„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯")
                return
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
            total_downloaded_size = sum(f['size'] for f in file_info_list)
            logger.info(f"Total downloaded size: {total_downloaded_size/1024/1024:.1f}MB")
            
            # Ù…Ø±Ø­Ù„Ù‡ 2: Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§
            await processing_msg.edit_text("ğŸ“¦ **Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø²ÛŒÙ¾...**\n\nâ³ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯", parse_mode=enums.ParseMode.MARKDOWN)
            
            file_info_list.sort(key=lambda x: x['size'], reverse=True)
            
            parts = []
            current_part = []
            current_size = 0
            
            for file_info in file_info_list:
                file_size = file_info['size']
                
                # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø¨Ù‡ ØªÙ†Ù‡Ø§ÛŒÛŒ Ø¨Ø²Ø±Ú¯ØªØ± Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø§Ø³Øª
                if file_size > Config.PART_SIZE * 0.8:
                    if current_part:
                        parts.append(current_part)
                        current_part = []
                        current_size = 0
                    parts.append([file_info])
                    logger.info(f"Large file in separate part: {file_info['name']} ({file_size/1024/1024:.1f}MB)")
                else:
                    if current_size + file_size > Config.PART_SIZE:
                        if current_part:
                            parts.append(current_part)
                            current_part = []
                            current_size = 0
                    
                    current_part.append(file_info)
                    current_size += file_size
            
            if current_part:
                parts.append(current_part)
            
            num_parts = len(parts)
            logger.info(f"Created {num_parts} parts from {len(file_info_list)} files")
            
            if num_parts == 0:
                await processing_msg.edit_text("âŒ **Ù‡ÛŒÚ† Ù¾Ø§Ø±ØªÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯**\n\nÙ„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯")
                return
            
            successful_parts = 0
            zip_paths = []
            
            # Ù…Ø±Ø­Ù„Ù‡ 3: ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ù‡Ø± Ù¾Ø§Ø±Øª
            for part_index, part_files in enumerate(parts):
                part_number = part_index + 1
                part_zip_name = f"{zip_name}_part{part_number}.zip"
                zip_path = os.path.join(tmp_dir, part_zip_name)
                zip_paths.append(zip_path)
                temp_files_to_cleanup.append(zip_path)
                
                part_password = zip_password
                part_size_mb = sum(f['size'] for f in part_files) / (1024 * 1024)
                
                logger.info(f"Processing part {part_number}/{num_parts}, "
                           f"files: {len(part_files)}, size: {part_size_mb:.1f}MB")
                
                await processing_msg.edit_text(
                    f"ğŸ—œï¸ **Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø±Øª {part_number}/{num_parts}**\n\n"
                    f"ğŸ“ Ø´Ø§Ù…Ù„ {len(part_files)} ÙØ§ÛŒÙ„\n"
                    f"ğŸ’¾ Ø­Ø¬Ù…: {part_size_mb:.1f}MB\n"
                    f"â³ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯...",
                    parse_mode=enums.ParseMode.MARKDOWN
                )
                
                # ØªÙ†Ø¸ÛŒÙ… progress tracker Ø¨Ø±Ø§ÛŒ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ
                total_part_size = sum(f['size'] for f in part_files)
                progress_tracker.reset(processing_msg, "ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ", f"Ù¾Ø§Ø±Øª {part_number}", part_number, num_parts)
                progress_tracker.total = total_part_size
                
                # ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø±Øª
                success = await create_zip_part_advanced(zip_path, part_files, part_password)
                if not success:
                    logger.error(f"Failed to create zip part {part_number}")
                    # Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ Ù¾Ø§Ø±Øª Ø¨Ø¹Ø¯ÛŒ
                    continue
                
                # Ø¢Ù¾Ù„ÙˆØ¯ Ù¾Ø§Ø±Øª
                upload_success = await upload_zip_part(
                    zip_path, 
                    part_index, 
                    num_parts, 
                    chat_id, 
                    message_id, 
                    part_password or "Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø²",
                    processing_msg
                )
                
                if upload_success:
                    successful_parts += 1
                    logger.info(f"Part {part_number} processed successfully")
                else:
                    logger.error(f"Failed to upload part {part_number}")
                
                await asyncio.sleep(2)
            
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª
            await cleanup_files(temp_files_to_cleanup)
            
            if successful_parts > 0:
                result_text = (
                    f"âœ… **Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!**\n\n"
                    f"ğŸ“¦ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: `{successful_parts}/{num_parts}`\n"
                    f"ğŸ”‘ Ø±Ù…Ø² Ø§ØµÙ„ÛŒ: `{zip_password or 'Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø²'}`\n\n"
                    f"ğŸ“Œ **Ù†Ú©Ø§Øª Ù…Ù‡Ù…:**\n"
                    f"â€¢ Ø¨Ø±Ø§ÛŒ extract Ù‡Ù…Ù‡ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯\n"
                    f"â€¢ Ø§Ø² Ø±Ù…Ø² ÛŒÚ©Ø³Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
                    f"â€¢ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø­Ø°Ù Ø´Ø¯Ù†Ø¯"
                )
            else:
                result_text = (
                    "âŒ **Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§**\n\n"
                    "ğŸ“Œ Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø®Ø±Ø§Ø¨ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯ ÛŒØ§ Ø­Ø¬Ù… Ø¨Ø³ÛŒØ§Ø± Ø²ÛŒØ§Ø¯ Ø¨Ø§Ø´Ø¯\n"
                    "ğŸ”„ Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ Ùˆ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯"
                )
            
            await safe_send_message(
                chat_id,
                result_text,
                reply_to_message_id=message_id,
                parse_mode=enums.ParseMode.MARKDOWN
            )
            
    except FloodWait as e:
        logger.warning(f"â° FloodWait Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²ÛŒÙ¾: {e.value} Ø«Ø§Ù†ÛŒÙ‡")
        
        if processing_msg:
            await processing_msg.edit_text(
                f"â³ **Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯**\n\n"
                f"ğŸ•’ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¹Ø¯ Ø§Ø²: {e.value} Ø«Ø§Ù†ÛŒÙ‡\n"
                f"âœ… Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø®ÙˆØ§Ù‡Ø¯ ÛŒØ§ÙØª",
                parse_mode=enums.ParseMode.MARKDOWN
            )
        
        schedule_task(process_zip_files, e.value + 15, user_id, zip_name, chat_id, message_id)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²ÛŒÙ¾: {e}", exc_info=True)
        if processing_msg:
            await processing_msg.edit_text(
                "âŒ **Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø® Ø¯Ø§Ø¯**\n\n"
                "ğŸ“Œ Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯",
                parse_mode=enums.ParseMode.MARKDOWN
            )
    finally:
        # Ù„ØºÙˆ task Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ù¾ÛŒØ´Ø±ÙØª
        if 'zip_progress_task' in locals():
            zip_progress_task.cancel()
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        await cleanup_files(temp_files_to_cleanup)
        
        if user_id in user_files:
            user_files[user_id] = []
        user_states.pop(user_id, None)
        user_states.pop(f"{user_id}_password", None)
        user_states.pop(f"{user_id}_zipname", None)
        save_user_data()

async def run_bot():
    global app
    logger.info("ğŸš€ Starting advanced zip/upload bot...")
    
    load_user_data()
    
    app = Client(
        "user_bot",
        api_id=Config.API_ID,
        api_hash=Config.API_HASH,
        session_string=Config.SESSION_STRING,
        in_memory=True
    )
    
    # Ø«Ø¨Øª Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§
    app.on_message(filters.command("start"))(start)
    app.on_message(filters.document | filters.video | filters.audio)(handle_file)
    app.on_message(filters.command("zip"))(start_zip)
    app.on_message(filters.command("zipnow"))(start_zip_now)
    app.on_message(filters.command("done"))(handle_done_command)
    app.on_message(filters.command("cancel"))(cancel_zip)
    app.on_message(filters.text & non_command)(process_zip)
    app.on_callback_query()(handle_callback_query)
    
    asyncio.create_task(process_scheduled_tasks())
    asyncio.create_task(process_task_queue())
    
    await app.start()
    logger.info("âœ… Bot started successfully with advanced features!")
    
    async def periodic_save():
        while True:
            await asyncio.sleep(300)
            save_user_data()
            logger.info("ğŸ’¾ User data saved periodically")
    
    asyncio.create_task(periodic_save())
    
    await asyncio.Event().wait()

if __name__ == "__main__":
    web_app = Flask(__name__)
    
    @web_app.route('/')
    def home():
        return "ğŸ¤– Advanced Zip/Upload Bot is Running", 200
    
    @web_app.route('/health')
    def health_check():
        return {
            "status": "healthy",
            "queue_size": len(task_queue),
            "scheduled_tasks": len(scheduled_tasks),
            "users_with_files": len(user_files),
            "timestamp": time.time()
        }, 200
    
    @web_app.route('/stats')
    def stats():
        total_files = sum(len(files) for files in user_files.values())
        total_size = sum(f["file_size"] for files in user_files.values() for f in files)
        return {
            "total_users": len(user_files),
            "total_files": total_files,
            "total_size": total_size,
            "formatted_size": progress_tracker.format_size(total_size)
        }, 200
    
    def start_bot():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(run_bot())
        except Exception as e:
            logger.error(f"Bot error: {e}")
        finally:
            loop.close()
            zip_executor.shutdown(wait=True)
    
    bot_thread = threading.Thread(target=start_bot, daemon=True)
    bot_thread.start()
    
    port = int(os.environ.get("PORT", 10000))
    logger.info(f"ğŸŒ Starting Flask web server on port {port}...")
    
    def run_web_app():
        web_app.run(host="0.0.0.0", port=port, debug=False, use_reloader=False)
    
    web_thread = threading.Thread(target=run_web_app, daemon=True)
    web_thread.start()
    
    try:
        bot_thread.join()
        web_thread.join()
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ Bot stopped by user")
        save_user_data()
        zip_executor.shutdown(wait=False)
        sys.exit(0)
