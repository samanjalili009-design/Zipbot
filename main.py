import os
import time
import tempfile
import pyzipper
import logging
import sys
import asyncio
import aiohttp
import aiofiles
from pyrogram import Client, filters, enums
from pyrogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton
from pyrogram.errors import FloodWait, RPCError, SessionPasswordNeeded
from flask import Flask
import threading
from collections import deque
import random
import math
from typing import Dict, List, Callable, Any, Tuple, Optional
from pathlib import Path
import json
from datetime import datetime
import shutil
from concurrent.futures import ThreadPoolExecutor, as_completed
import queue

# ===== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ =====
class Config:
    API_ID = 26180086
    API_HASH = "d91e174c7faf0e5a6a3a2ecb0b3361f6"
    SESSION_STRING = "BAGPefYAEAaXaj52wzDLPF0RSfWtF_Slk8nFWzYAHS9vu-HBxRUz9yLnq7m8z-ajYCQxQZO-5aNX0he9OttDjmjieYDMbDjBJtbsOT2ZwsQNe8UCAo5oFPveD5V1H0cIBMlXCG1P49G2oonf1YL1r16Nt34AJLkmzDIoFD0hhxwVBXvrUGwZmEoTtdkfORCYUMGACKO4-Al-NH35oVCkTIqmXQ5DUp9PVx6DND243VW5Xcqay7qwrwfoS4sWRA-7TMXykbHa37ZsdcCOf0VS8e6PyaYvG5BjMCd9BGRnR9IImrksYY2uBM2Bg42MLaa1WFxQtn97p5ViPF9c1MpY49bc5Gm5lwAAAAF--TK5AA"
    ALLOWED_USER_IDS = [417536686]
    MAX_FILE_SIZE = 2147483648  # 2GB
    MAX_TOTAL_SIZE = 4294967296  # 4GB
    PART_SIZE = 400 * 1024 * 1024  # 400MB
    CHUNK_SIZE = 512 * 1024  # 512KB
    MAX_CONCURRENT_DOWNLOADS = 1
    MAX_CONCURRENT_UPLOADS = 1
    RETRY_DELAY = 10
    PROGRESS_UPDATE_INTERVAL = 1.0
    DATA_FILE = "user_data.json"
    UPLOAD_CHUNK_SIZE = 2 * 1024 * 1024  # 2MB Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯
    MAX_UPLOAD_RETRIES = 3
    ZIP_COMPRESSION_LEVEL = 3
    MAX_ZIP_RETRIES = 2
    ZIP_BASE_TIMEOUT = 1800
    ZIP_TIMEOUT_PER_GB = 900
    MEMORY_LIMIT = 450 * 1024 * 1024
    STREAMING_CHUNK_SIZE = 4 * 1024 * 1024
    UPLOAD_PART_SIZE = 100 * 1024 * 1024  # 100MB - Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù‡Ø± Ù‚Ø³Ù…Øª Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯

# ===== Ù„Ø§Ú¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("bot.log", encoding="utf-8")
    ]
)
logger = logging.getLogger(__name__)

# ===== Ú©Ù„Ø§ÛŒÙ†Øª Pyrogram =====
app = None

# ===== Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ ÙˆØ¶Ø¹ÛŒØª =====
user_files: Dict[int, List] = {}
user_states: Dict[int, Any] = {}
scheduled_tasks: List[Tuple[float, Callable, Tuple, Dict]] = []
task_queue = deque()
processing = False
download_semaphore = asyncio.Semaphore(Config.MAX_CONCURRENT_DOWNLOADS)
upload_semaphore = asyncio.Semaphore(Config.MAX_CONCURRENT_UPLOADS)
zip_executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="ZipWorker")

# ===== Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ´Ø±ÙØª =====
class ProgressTracker:
    def __init__(self):
        self.start_time = time.time()
        self.last_update = 0
        self.last_text = ""
        self.last_percent = 0
        self.current = 0
        self.total = 0
        self.stage = ""
        self.file_name = ""
        self.message = None
        self.file_index = 0
        self.total_files = 0
        self.lock = asyncio.Lock()
        self.zip_progress_queue = queue.Queue()
        self.upload_progress_queue = queue.Queue()
        self.is_uploading = False

    def reset(self, message: Message = None, stage: str = "", file_name: str = "", file_index: int = 0, total_files: int = 0):
        self.start_time = time.time()
        self.last_update = 0
        self.last_text = ""
        self.last_percent = 0
        self.current = 0
        self.total = 0
        self.stage = stage
        self.file_name = file_name
        self.message = message
        self.file_index = file_index
        self.total_files = total_files
        self.is_uploading = (stage == "Ø¢Ù¾Ù„ÙˆØ¯")

    async def update(self, current: int, total: int):
        try:
            async with self.lock:
                now = time.time()
                
                # Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ØŒ Ù‡Ù…ÛŒØ´Ù‡ Ø¢Ù¾Ø¯ÛŒØª Ú©Ù†ÛŒÙ… Ø­ØªÛŒ Ø§Ú¯Ø± Ø²Ù…Ø§Ù† Ù†Ø±Ø³ÛŒØ¯Ù‡
                update_interval = Config.PROGRESS_UPDATE_INTERVAL
                if self.is_uploading:
                    update_interval = 0.3  # Ø¢Ù¾Ø¯ÛŒØª Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯
                
                if now - self.last_update < update_interval and current != total:
                    return
                
                self.current = current
                self.total = total
                self.last_update = now
                
                percent = (current / total) * 100 if total > 0 else 0
                elapsed = now - self.start_time
                speed = current / elapsed if elapsed > 0 else 0
                eta = (total - current) / speed if speed > 0 and current > 0 else 0
                
                # Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ØŒ Ù‡Ù…ÛŒØ´Ù‡ Ø¢Ù¾Ø¯ÛŒØª Ú©Ù†ÛŒÙ…
                if not self.is_uploading and abs(percent - self.last_percent) < 1.0 and current != total:
                    return
                
                self.last_percent = percent
                
                bar = self.get_progress_bar(percent)
                
                if self.total_files > 1:
                    progress_text = (
                        f"ğŸš€ **{self.stage} ÙØ§ÛŒÙ„ {self.file_index}/{self.total_files}**\n\n"
                        f"{bar}\n\n"
                        f"ğŸ“ ÙØ§ÛŒÙ„: `{self.file_name[:25]}{'...' if len(self.file_name) > 25 else ''}`\n"
                        f"ğŸ“Š Ù¾ÛŒØ´Ø±ÙØª: `{self.format_size(current)} / {self.format_size(total)}`\n"
                        f"âš¡ Ø³Ø±Ø¹Øª: `{self.format_size(speed)}/s`\n"
                        f"â° Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: `{self.format_time(int(eta))}`"
                    )
                else:
                    progress_text = (
                        f"ğŸš€ **{self.stage}**\n\n"
                        f"{bar}\n\n"
                        f"ğŸ“ ÙØ§ÛŒÙ„: `{self.file_name[:25]}{'...' if len(self.file_name) > 25 else ''}`\n"
                        f"ğŸ“Š Ù¾ÛŒØ´Ø±ÙØª: `{self.format_size(current)} / {self.format_size(total)}`\n"
                        f"âš¡ Ø³Ø±Ø¹Øª: `{self.format_size(speed)}/s`\n"
                        f"â° Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: `{self.format_time(int(eta))}`"
                    )
                
                if self.last_text != progress_text and self.message:
                    try:
                        await self.message.edit_text(progress_text, parse_mode=enums.ParseMode.MARKDOWN)
                        self.last_text = progress_text
                    except Exception as e:
                        logger.error(f"Error updating progress: {e}")
                        
        except Exception as e:
            logger.error(f"Progress update error: {e}")

    async def update_zip_progress(self):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        try:
            while True:
                try:
                    current, total = self.zip_progress_queue.get_nowait()
                    await self.update(current, total)
                except queue.Empty:
                    await asyncio.sleep(0.5)
        except Exception as e:
            logger.error(f"Zip progress update error: {e}")

    async def update_upload_progress(self, current: int, total: int):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø¢Ù¾Ù„ÙˆØ¯"""
        try:
            await self.update(current, total)
        except Exception as e:
            logger.error(f"Upload progress update error: {e}")

    @staticmethod
    def get_progress_bar(percentage: float, length: int = 15) -> str:
        filled = int(length * percentage / 100)
        bar = "â¬¢" * filled + "â¬¡" * (length - filled)
        return f"{bar} {percentage:.1f}%"

    @staticmethod
    def format_size(size_bytes: int) -> str:
        if size_bytes == 0:
            return "0B"
        size_names = ["B", "KB", "MB", "GB", "TB"]
        i = int(math.floor(math.log(size_bytes, 1024)))
        p = math.pow(1024, i)
        s = round(size_bytes / p, 2)
        return f"{s} {size_names[i]}"

    @staticmethod
    def format_time(seconds: int) -> str:
        if seconds < 60:
            return f"{seconds} Ø«Ø§Ù†ÛŒÙ‡"
        elif seconds < 3600:
            return f"{seconds // 60} Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ {seconds % 60} Ø«Ø§Ù†ÛŒÙ‡"
        else:
            return f"{seconds // 3600} Ø³Ø§Ø¹Øª Ùˆ {(seconds % 3600) // 60} Ø¯Ù‚ÛŒÙ‚Ù‡"

# Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ù¾ÛŒØ´Ø±ÙØª
progress_tracker = ProgressTracker()

# ===== ÙØ§Ù†Ú©Ø´Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ =====
def is_user_allowed(user_id: int) -> bool:
    return user_id in Config.ALLOWED_USER_IDS

def load_user_data():
    global user_files, user_states
    try:
        if os.path.exists(Config.DATA_FILE):
            with open(Config.DATA_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                user_files = {int(k): v for k, v in data.get('user_files', {}).items()}
                user_states = {int(k): v for k, v in data.get('user_states', {}).items()}
                logger.info("User data loaded successfully")
    except Exception as e:
        logger.error(f"Error loading user data: {e}")

def save_user_data():
    try:
        data = {
            'user_files': user_files,
            'user_states': user_states
        }
        with open(Config.DATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Error saving user data: {e}")

async def safe_send_message(chat_id, text, reply_to_message_id=None, reply_markup=None, parse_mode=None):
    max_retries = 2
    for attempt in range(max_retries):
        try:
            await asyncio.sleep(random.uniform(1.0, 2.0))
            return await app.send_message(
                chat_id, 
                text, 
                reply_to_message_id=reply_to_message_id,
                reply_markup=reply_markup,
                parse_mode=parse_mode
            )
        except FloodWait as e:
            wait_time = e.value + random.uniform(1, 3)
            logger.warning(f"FloodWait: {wait_time} seconds (attempt {attempt + 1}/{max_retries})")
            await asyncio.sleep(wait_time)
        except Exception as e:
            logger.error(f"Error sending message (attempt {attempt + 1}): {e}")
            await asyncio.sleep(1)
    
    try:
        return await app.send_message(
            chat_id, 
            text, 
            reply_to_message_id=reply_to_message_id,
            reply_markup=reply_markup
        )
    except Exception as e:
        logger.error(f"Failed to send message even without parse_mode: {e}")
        return None

async def safe_download_media(message, file_path, file_name="", file_index=0, total_files=0, processing_msg=None):
    max_retries = 2
    for attempt in range(max_retries):
        try:
            async with download_semaphore:
                await asyncio.sleep(random.uniform(0.5, 1.5))
                
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                
                progress_tracker.reset(processing_msg, "Ø¯Ø§Ù†Ù„ÙˆØ¯", file_name, file_index, total_files)
                
                await app.download_media(
                    message,
                    file_name=file_path,
                    progress=progress_tracker.update
                )
                
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    return True
                else:
                    logger.warning(f"Downloaded file is empty or missing (attempt {attempt + 1})")
                    
        except FloodWait as e:
            wait_time = e.value + random.uniform(3, 7)
            logger.warning(f"Download FloodWait: {wait_time} seconds (attempt {attempt + 1})")
            await asyncio.sleep(wait_time)
        except (RPCError, aiohttp.ClientError, OSError) as e:
            logger.error(f"Download error (attempt {attempt + 1}): {e}")
            await asyncio.sleep(Config.RETRY_DELAY)
        except Exception as e:
            logger.error(f"Unexpected download error (attempt {attempt + 1}): {e}")
            await asyncio.sleep(Config.RETRY_DELAY)
    
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
    except:
        pass
    
    return False

def schedule_task(task_func: Callable, delay: float, *args, **kwargs):
    execution_time = time.time() + delay
    scheduled_tasks.append((execution_time, task_func, args, kwargs))
    scheduled_tasks.sort(key=lambda x: x[0])

async def process_scheduled_tasks():
    while True:
        now = time.time()
        tasks_to_run = []
        
        for i, (execution_time, task_func, args, kwargs) in enumerate(scheduled_tasks):
            if execution_time <= now:
                tasks_to_run.append((task_func, args, kwargs))
                scheduled_tasks.pop(i)
            else:
                break
        
        for task_func, args, kwargs in tasks_to_run:
            try:
                if asyncio.iscoroutinefunction(task_func):
                    await task_func(*args, **kwargs)
                else:
                    await asyncio.to_thread(task_func, *args, **kwargs)
            except Exception as e:
                logger.error(f"Scheduled task error: {e}")
        
        await asyncio.sleep(2)

async def process_task_queue():
    global processing
    
    while True:
        if not task_queue:
            await asyncio.sleep(2)
            continue
        
        processing = True
        task_func, args, kwargs = task_queue.popleft()
        
        try:
            if asyncio.iscoroutinefunction(task_func):
                await task_func(*args, **kwargs)
            else:
                await asyncio.to_thread(task_func, *args, **kwargs)
            
            await asyncio.sleep(random.uniform(2.0, 4.0))
            
        except FloodWait as e:
            wait_time = e.value + random.uniform(5, 10)
            logger.warning(f"ğŸ•’ FloodWait detected: {wait_time} seconds. Rescheduling task...")
            
            schedule_task(task_func, wait_time, *args, **kwargs)
            
            user_id = kwargs.get('user_id', args[0] if args else None)
            if user_id:
                await notify_user_floodwait(user_id, wait_time)
            
            await asyncio.sleep(3)
            
        except Exception as e:
            logger.error(f"Task error: {e}")
            await asyncio.sleep(3)
        
        finally:
            processing = False
            save_user_data()

def add_to_queue(task_func: Callable, *args, **kwargs):
    task_queue.append((task_func, args, kwargs))
    logger.info(f"Task added to queue. Queue size: {len(task_queue)}")

async def notify_user_floodwait(user_id: int, wait_time: int):
    try:
        wait_minutes = wait_time // 60
        wait_seconds = wait_time % 60
        
        await safe_send_message(
            user_id,
            f"â³ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù…ÙˆÙ‚Øª ØªÙ„Ú¯Ø±Ø§Ù…ØŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯.\n"
            f"ğŸ•’ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±: {wait_minutes} Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ {wait_seconds} Ø«Ø§Ù†ÛŒÙ‡\n"
            f"âœ… Ø¨Ø¹Ø¯ Ø§Ø² Ø§ÛŒÙ† Ø²Ù…Ø§Ù†ØŒ Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯."
        )
    except Exception as e:
        logger.error(f"Error notifying user about floodwait: {e}")

def calculate_zip_timeout(total_size_mb: float) -> int:
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ timeout Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø¬Ù… ÙØ§ÛŒÙ„"""
    base_timeout = Config.ZIP_BASE_TIMEOUT
    additional_time = max(0, (total_size_mb - 1024) / 1024 * Config.ZIP_TIMEOUT_PER_GB)
    total_timeout = min(base_timeout + additional_time, 3 * 3600)
    logger.info(f"Calculated zip timeout: {total_timeout/60:.1f} minutes for {total_size_mb:.1f}MB")
    return int(total_timeout)

def zip_creation_task_streaming(zip_path: str, files: List[Dict], password: Optional[str], progress_queue: queue.Queue) -> bool:
    """ØªØ§Ø¨Ø¹ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø±ÛŒØ§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ú©Ù…ØªØ±"""
    try:
        total_size = sum(f['size'] for f in files)
        processed_size = 0
        
        logger.info(f"Starting streaming zip creation for {len(files)} files, total size: {total_size/1024/1024:.1f}MB")
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        for file_info in files:
            if not os.path.exists(file_info['path']):
                logger.error(f"File not found: {file_info['path']}")
                return False
            if os.path.getsize(file_info['path']) == 0:
                logger.error(f"File is empty: {file_info['path']}")
                return False
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§Ù„Øª Ø¨Ø¯ÙˆÙ† ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù‚Ø¨Ù„ ÙØ´Ø±Ø¯Ù‡
        compression = pyzipper.ZIP_STORED if any(f['name'].lower().endswith(('.zip', '.rar', '.7z', '.tar', '.gz')) for f in files) else pyzipper.ZIP_DEFLATED
        
        with pyzipper.AESZipFile(
            zip_path, 
            "w", 
            compression=compression,
            compresslevel=Config.ZIP_COMPRESSION_LEVEL,
            encryption=pyzipper.WZ_AES if password else None,
            allowZip64=True
        ) as zipf:
            
            if password:
                try:
                    zipf.setpassword(password.encode('utf-8'))
                    logger.info("Password set successfully")
                except Exception as e:
                    logger.error(f"Error setting password: {e}")
                    return False
            
            for file_info in files:
                file_path = file_info['path']
                arcname = os.path.basename(file_info['name'])
                
                if not os.path.exists(file_path):
                    logger.error(f"File disappeared during processing: {file_path}")
                    continue
                
                try:
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø¨Ù‡ Ø²ÛŒÙ¾ Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ø±ÛŒØ§Ù†ÛŒ
                    with open(file_path, 'rb') as f:
                        with zipf.open(arcname, 'w') as zf:
                            while True:
                                chunk = f.read(Config.STREAMING_CHUNK_SIZE)
                                if not chunk:
                                    break
                                zf.write(chunk)
                                processed_size += len(chunk)
                                progress_queue.put((processed_size, total_size))
                                logger.debug(f"Added chunk of {len(chunk)} bytes from {arcname}, progress: {processed_size}/{total_size}")
                    
                    logger.info(f"Successfully added {arcname} to zip")
                    
                except Exception as e:
                    logger.error(f"Error adding file {arcname} to zip: {e}")
                    continue
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾
        if os.path.exists(zip_path) and os.path.getsize(zip_path) > 0:
            zip_size = os.path.getsize(zip_path)
            compression_ratio = (1 - (zip_size / total_size)) * 100 if total_size > 0 else 0
            logger.info(f"Zip created successfully: {zip_path}, "
                       f"size: {zip_size/1024/1024:.1f}MB, "
                       f"compression: {compression_ratio:.1f}%")
            
            # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø³Ø§Ø¯Ù‡
            try:
                with pyzipper.AESZipFile(zip_path, 'r') as test_zip:
                    if password:
                        test_zip.setpassword(password.encode('utf-8'))
                    test_zip.testzip()
                    logger.info("Zip validation passed")
                    return True
            except Exception as test_error:
                logger.error(f"Zip validation failed: {test_error}")
                return False
        else:
            logger.error("Created zip file is empty or missing")
            return False
            
    except Exception as e:
        logger.error(f"Error in zip creation: {e}", exc_info=True)
        try:
            if os.path.exists(zip_path):
                os.remove(zip_path)
        except:
            pass
        return False

async def create_zip_part_advanced(zip_path: str, files: List[Dict], default_password: Optional[str] = None) -> bool:
    """ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÙØ´Ø±Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ Ùˆ timeout"""
    max_retries = Config.MAX_ZIP_RETRIES
    
    for attempt in range(max_retries):
        try:
            os.makedirs(os.path.dirname(zip_path), exist_ok=True)
            
            if os.path.exists(zip_path):
                try:
                    os.remove(zip_path)
                    logger.info(f"Removed existing zip file: {zip_path}")
                except Exception as e:
                    logger.error(f"Error removing existing zip: {e}")
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹
            missing_files = []
            empty_files = []
            for file_info in files:
                if not os.path.exists(file_info['path']):
                    missing_files.append(file_info['name'])
                    logger.error(f"File not found: {file_info['path']}")
                elif os.path.getsize(file_info['path']) == 0:
                    empty_files.append(file_info['name'])
                    logger.error(f"File is empty: {file_info['path']}")
            
            if missing_files or empty_files:
                logger.error(f"Problematic files - Missing: {missing_files}, Empty: {empty_files}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(3)
                    continue
                else:
                    return False
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ timeout Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø¬Ù…
            total_size_mb = sum(f['size'] for f in files) / (1024 * 1024)
            dynamic_timeout = calculate_zip_timeout(total_size_mb)
            
            logger.info(f"Zip attempt {attempt + 1}/{max_retries} for {len(files)} files, "
                       f"total: {total_size_mb:.1f}MB, timeout: {dynamic_timeout/60:.1f}min")
            
            loop = asyncio.get_event_loop()
            
            success = await asyncio.wait_for(
                loop.run_in_executor(
                    zip_executor, 
                    zip_creation_task_streaming, 
                    zip_path, files, default_password, progress_tracker.zip_progress_queue
                ),
                timeout=dynamic_timeout
            )
            
            if success:
                if os.path.exists(zip_path) and os.path.getsize(zip_path) > 0:
                    logger.info(f"Zip part created successfully: {zip_path}, "
                               f"size: {os.path.getsize(zip_path)/1024/1024:.1f}MB")
                    return True
                else:
                    logger.error("Zip file created but is empty or missing")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(2)
                        continue
            
        except asyncio.TimeoutError:
            logger.error(f"Zip creation timeout (attempt {attempt + 1}/{max_retries})")
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
                    logger.info("Removed timeout zip file")
            except Exception as e:
                logger.error(f"Error removing timeout zip file: {e}")
            
            if attempt < max_retries - 1:
                retry_delay = random.uniform(5, 15)
                logger.info(f"Retrying after timeout in {retry_delay:.1f} seconds...")
                await asyncio.sleep(retry_delay)
                
        except Exception as e:
            logger.error(f"Unexpected error in zip creation (attempt {attempt + 1}/{max_retries}): {e}", exc_info=True)
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
            except:
                pass
            
            if attempt < max_retries - 1:
                retry_delay = random.uniform(2, 8)
                logger.info(f"Retrying after error in {retry_delay:.1f} seconds...")
                await asyncio.sleep(retry_delay)
    
    logger.error(f"All {max_retries} zip attempts failed")
    return False

async def upload_large_file_chunked(file_path: str, chat_id: int, caption: str, reply_to_message_id: int, 
                                  progress_callback, progress_args) -> bool:
    """Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø¨Ù‡ ØµÙˆØ±Øª ØªÚ©Ù‡ ØªÚ©Ù‡"""
    max_retries = Config.MAX_UPLOAD_RETRIES
    
    for attempt in range(max_retries):
        try:
            async with upload_semaphore:
                if attempt > 0:
                    wait_time = random.uniform(5, 15)
                    logger.info(f"Upload retry {attempt + 1}/{max_retries} after {wait_time:.1f} seconds")
                    await asyncio.sleep(wait_time)
                
                file_size = os.path.getsize(file_path)
                
                # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú© Ø§Ø³ØªØŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†
                if file_size <= Config.UPLOAD_PART_SIZE:
                    await app.send_document(
                        chat_id=chat_id,
                        document=file_path,
                        caption=caption,
                        reply_to_message_id=reply_to_message_id,
                        progress=progress_callback,
                        progress_args=progress_args
                    )
                else:
                    # ÙØ§ÛŒÙ„ Ø¨Ø²Ø±Ú¯ Ø§Ø³ØªØŒ Ø¨Ø§ÛŒØ¯ ØªÚ©Ù‡ ØªÚ©Ù‡ Ø¢Ù¾Ù„ÙˆØ¯ Ø´ÙˆØ¯
                    await upload_file_in_parts(file_path, chat_id, caption, reply_to_message_id, progress_callback, progress_args)
                
                logger.info(f"File uploaded successfully: {file_path}")
                return True
                
        except FloodWait as e:
            wait_time = e.value + random.uniform(3, 10)
            logger.warning(f"Upload FloodWait: {wait_time} seconds (attempt {attempt + 1}/{max_retries})")
            
            if attempt == max_retries - 1:
                logger.error(f"Max retries reached for upload: {file_path}")
                return False
                
            await asyncio.sleep(wait_time)
            
        except RPCError as e:
            logger.error(f"RPCError during upload (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return False
            await asyncio.sleep(Config.RETRY_DELAY)
            
        except OSError as e:
            logger.error(f"OSError during upload (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return False
            await asyncio.sleep(Config.RETRY_DELAY)
            
        except Exception as e:
            logger.error(f"Unexpected error during upload (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return False
            await asyncio.sleep(Config.RETRY_DELAY)
    
    return False

async def upload_file_in_parts(file_path: str, chat_id: int, caption: str, reply_to_message_id: int,
                             progress_callback, progress_args):
    """Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø¨Ù‡ ØµÙˆØ±Øª ØªÚ©Ù‡ ØªÚ©Ù‡"""
    file_size = os.path.getsize(file_path)
    part_size = Config.UPLOAD_PART_SIZE
    total_parts = (file_size + part_size - 1) // part_size
    
    logger.info(f"Uploading file in {total_parts} parts, part size: {part_size/1024/1024:.1f}MB")
    
    # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù‚Ø³Ù…Øª
    temp_parts = []
    
    try:
        with open(file_path, 'rb') as f:
            for part_num in range(total_parts):
                part_data = f.read(part_size)
                if not part_data:
                    break
                    
                # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù‚Ø³Ù…Øª
                temp_part_path = f"{file_path}_part{part_num + 1}"
                with open(temp_part_path, 'wb') as part_file:
                    part_file.write(part_data)
                
                temp_parts.append(temp_part_path)
                
                # Ø¢Ù¾Ù„ÙˆØ¯ Ø§ÛŒÙ† Ù‚Ø³Ù…Øª
                part_caption = f"{caption} - Ù‚Ø³Ù…Øª {part_num + 1}/{total_parts}"
                
                await app.send_document(
                    chat_id=chat_id,
                    document=temp_part_path,
                    caption=part_caption,
                    reply_to_message_id=reply_to_message_id,
                    progress=progress_callback,
                    progress_args=progress_args
                )
                
                logger.info(f"Uploaded part {part_num + 1}/{total_parts}")
                
                # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ø§ÛŒÙ† Ù‚Ø³Ù…Øª
                try:
                    os.remove(temp_part_path)
                    temp_parts.remove(temp_part_path)
                except:
                    pass
                
                await asyncio.sleep(1)  # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† Ø¢Ù¾Ù„ÙˆØ¯ Ù‚Ø³Ù…ØªÙ‡Ø§
        
        logger.info(f"All {total_parts} parts uploaded successfully")
        
    except Exception as e:
        logger.error(f"Error in chunked upload: {e}")
        raise
    finally:
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯
        for temp_part in temp_parts:
            try:
                if os.path.exists(temp_part):
                    os.remove(temp_part)
            except:
                pass

async def upload_zip_part(zip_path: str, part_number: int, total_parts: int, 
                         chat_id: int, message_id: int, password: str, processing_msg: Message):
    try:
        if not os.path.exists(zip_path) or os.path.getsize(zip_path) == 0:
            logger.error(f"Zip file not found or empty: {zip_path}")
            return False
            
        part_size = os.path.getsize(zip_path)
        
        progress_tracker.reset(processing_msg, "Ø¢Ù¾Ù„ÙˆØ¯", f"Ù¾Ø§Ø±Øª {part_number + 1}", part_number + 1, total_parts)
        
        caption = (
            f"ğŸ“¦ Ù¾Ø§Ø±Øª {part_number + 1}/{total_parts}\n"
            f"ğŸ”‘ Ø±Ù…Ø²: `{password}`\n"
            f"ğŸ’¾ Ø­Ø¬Ù…: {progress_tracker.format_size(part_size)}"
        )
        
        success = await upload_large_file_chunked(
            file_path=zip_path,
            chat_id=chat_id,
            caption=caption,
            reply_to_message_id=message_id,
            progress_callback=progress_tracker.update_upload_progress,
            progress_args=()
        )
        
        if success:
            logger.info(f"Part {part_number + 1}/{total_parts} uploaded successfully")
            await asyncio.sleep(random.uniform(2.0, 5.0))
            return True
        else:
            logger.error(f"Failed to upload part {part_number + 1}/{total_parts}")
            return False
            
    except FloodWait as e:
        wait_time = e.value + random.uniform(5, 15)
        logger.warning(f"Upload FloodWait in main function: {wait_time} seconds")
        
        schedule_task(
            upload_zip_part, 
            wait_time, 
            zip_path, part_number, total_parts, 
            chat_id, message_id, password, processing_msg
        )
        
        try:
            await processing_msg.edit_text(
                f"â³ **Ø¢Ù¾Ù„ÙˆØ¯ Ù…ØªÙˆÙ‚Ù Ø´Ø¯**\n\n"
                f"ğŸ“¦ Ù¾Ø§Ø±Øª: {part_number + 1}/{total_parts}\n"
                f"ğŸ•’ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¹Ø¯ Ø§Ø²: {wait_time:.0f} Ø«Ø§Ù†ÛŒÙ‡\n"
                f"âœ… Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø®ÙˆØ§Ù‡Ø¯ ÛŒØ§ÙØª",
                parse_mode=enums.ParseMode.MARKDOWN
            )
        except:
            pass
            
        return False
        
    except Exception as e:
        logger.error(f"Error uploading part {part_number}: {e}")
        return False

async def cleanup_files(file_paths: List[str]):
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª"""
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                if os.path.isdir(file_path):
                    shutil.rmtree(file_path)
                else:
                    os.remove(file_path)
                logger.info(f"Cleaned up file: {file_path}")
        except Exception as e:
            logger.error(f"Error cleaning up file {file_path}: {e}")

# ===== Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ =====
async def start(client, message: Message):
    if not is_user_allowed(message.from_user.id):
        return
    
    welcome_text = (
        "ğŸ‘‹ **Ø³Ù„Ø§Ù…! Ø¨Ù‡ Ø±Ø¨Ø§Øª Ø²ÛŒÙ¾ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯**\n\n"
        "âœ¨ **Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø±Ø¨Ø§Øª:**\n"
        "â€¢ ğŸ”’ Ø²ÛŒÙ¾ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ AES-256\n"
        "â€¢ ğŸ“¦ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ 400 Ù…Ú¯Ø§Ø¨Ø§ÛŒØªÛŒ\n"
        "â€¢ âš¡ Ø¢Ù¾Ù„ÙˆØ¯ ØªÚ©Ù‡ ØªÚ©Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯\n"
        "â€¢ ğŸ›¡ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…\n"
        "â€¢ ğŸ“Š Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ\n\n"
        "ğŸ“ **Ø±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡:**\n"
        "1. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
        "2. Ø§Ø² Ú©Ù¾Ø´Ù† `pass=Ø±Ù…Ø²` Ø¨Ø±Ø§ÛŒ Ø±Ù…Ø² Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù‡Ø± ÙØ§ÛŒÙ„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
        "3. Ø¯Ø³ØªÙˆØ± /zip Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\n\n"
        f"âš™ï¸ **Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§:**\n"
        f"â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± Ø­Ø¬Ù… Ù‡Ø± ÙØ§ÛŒÙ„: {progress_tracker.format_size(Config.MAX_FILE_SIZE)}\n"
        f"â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± Ø­Ø¬Ù… Ú©Ù„: {progress_tracker.format_size(Config.MAX_TOTAL_SIZE)}\n\n"
        "ğŸ›  Ø¨Ø±Ø§ÛŒ Ù„ØºÙˆ Ø¹Ù…Ù„ÛŒØ§Øª Ø§Ø² /cancel Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"
    )
    
    keyboard = InlineKeyboardMarkup([
        [InlineKeyboardButton("ğŸ“¦ Ø´Ø±ÙˆØ¹ Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„", callback_data="start_upload")],
        [InlineKeyboardButton("â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„", callback_data="help")]
    ])
    
    await safe_send_message(
        message.chat.id,
        welcome_text,
        reply_to_message_id=message.id,
        reply_markup=keyboard,
        parse_mode=enums.ParseMode.MARKDOWN
    )

async def handle_file(client, message: Message):
    if not is_user_allowed(message.from_user.id):
        return
    
    if not message.document and not message.video and not message.audio:
        return
    
    if message.document:
        file_obj = message.document
        file_type = "document"
    elif message.video:
        file_obj = message.video
        file_type = "video"
    elif message.audio:
        file_obj = message.audio
        file_type = "audio"
    else:
        return
    
    file_name = getattr(file_obj, 'file_name', None) or f"{file_type}_{message.id}"
    file_size = file_obj.file_size
    caption = message.caption or ""
    password = None
    
    if "pass=" in caption:
        password_match = caption.split("pass=", 1)[1].split()[0].strip()
        if password_match:
            password = password_match
    
    if file_size > Config.MAX_FILE_SIZE:
        await safe_send_message(
            message.chat.id,
            f"âŒ **Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø§Ø³Øª!**\n\n"
            f"ğŸ“¦ Ø­Ø¬Ù… ÙØ§ÛŒÙ„: {progress_tracker.format_size(file_size)}\n"
            f"âš–ï¸ Ø­Ø¯ Ù…Ø¬Ø§Ø²: {progress_tracker.format_size(Config.MAX_FILE_SIZE)}",
            reply_to_message_id=message.id
        )
        return
    
    user_id = message.from_user.id
    if user_id not in user_files:
        user_files[user_id] = []
    
    existing_files = [f['file_name'] for f in user_files[user_id]]
    if file_name in existing_files:
        base, ext = os.path.splitext(file_name)
        file_name = f"{base}_{message.id}{ext}"
    
    user_files[user_id].append({
        "message_id": message.id,
        "file_name": file_name, 
        "password": password, 
        "file_size": file_size,
        "file_type": file_type,
        "added_time": time.time()
    })
    
    total_size = sum(f["file_size"] for f in user_files[user_id])
    file_count = len(user_files[user_id])
    
    await safe_send_message(
        message.chat.id,
        f"âœ… **ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯**\n\n"
        f"ğŸ“ Ù†Ø§Ù…: `{file_name}`\n"
        f"ğŸ“¦ Ø­Ø¬Ù…: `{progress_tracker.format_size(file_size)}`\n"
        f"ğŸ”‘ Ø±Ù…Ø²: `{password if password else 'âŒ Ù†Ø¯Ø§Ø±Ø¯'}`\n\n"
        f"ğŸ“Š ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ: `{file_count}` ÙØ§ÛŒÙ„ (`{progress_tracker.format_size(total_size)}`)\n\n"
        f"ğŸ“Œ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø²ÛŒÙ¾ Ø§Ø² `/zip` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯",
        reply_to_message_id=message.id,
        parse_mode=enums.ParseMode.MARKDOWN
    )
    
    save_user_data()

async def start_zip(client, message: Message):
    if not is_user_allowed(message.from_user.id):
        return
    
    user_id = message.from_user.id
    if user_id not in user_files or not user_files[user_id]:
        await safe_send_message(
            message.chat.id,
            "âŒ **Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø²ÛŒÙ¾ Ú©Ø±Ø¯Ù† ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯**\n\n"
            "ğŸ“ Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯",
            reply_to_message_id=message.id
        )
        return
    
    total_size = sum(f["file_size"] for f in user_files[user_id])
    if total_size > Config.MAX_TOTAL_SIZE:
        await safe_send_message(
            message.chat.id,
            f"âŒ **Ø­Ø¬Ù… Ú©Ù„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø§Ø³Øª!**\n\n"
            f"ğŸ“¦ Ø­Ø¬Ù… Ú©Ù„: {progress_tracker.format_size(total_size)}\n"
            f"âš–ï¸ Ø­Ø¯ Ù…Ø¬Ø§Ø²: {progress_tracker.format_size(Config.MAX_TOTAL_SIZE)}\n\n"
            f"ğŸ“Œ Ù„Ø·ÙØ§Ù‹ ØªØ¹Ø¯Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯",
            reply_to_message_id=message.id
        )
        user_files[user_id] = []
        save_user_data()
        return
    
    user_states[user_id] = "waiting_password"
    
    await safe_send_message(
        message.chat.id,
        "ğŸ” **Ù„Ø·ÙØ§Ù‹ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:**\n\n"
        "ğŸ“ Ù¾Ø³ Ø§Ø² ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø±Ù…Ø²ØŒ Ø§Ø² /done Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
        "âš ï¸ ØªÙˆØ¬Ù‡: Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ 4 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯",
        reply_to_message_id=message.id
    )

async def start_zip_now(client, message: Message):
    user_id = message.from_user.id
    
    if not is_user_allowed(user_id):
        return
    
    if user_states.get(user_id) != "ready_to_zip":
        await message.reply("âŒ Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ Ù…Ø±Ø§Ø­Ù„ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ú©Ø§Ù…Ù„ Ú©Ù†ÛŒØ¯")
        return
    
    zip_name = user_states.get(f"{user_id}_zipname", f"archive_{int(time.time())}")
    
    add_to_queue(process_zip_files, user_id, zip_name, message.chat.id, message.id)
    
    await message.reply("âœ… **Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø²ÛŒÙ¾ Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.**\n\nâ³ Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒØ´ÙˆØ¯...")

async def cancel_zip(client, message: Message):
    user_id = message.from_user.id
    if user_id in user_files:
        user_files[user_id] = []
    
    user_states.pop(user_id, None)
    user_states.pop(f"{user_id}_password", None)
    user_states.pop(f"{user_id}_zipname", None)
    
    save_user_data()
    
    await safe_send_message(
        message.chat.id,
        "âŒ **Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯**\n\n"
        "âœ… Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ù¾Ø§Ú© Ø´Ø¯Ù†Ø¯\n"
        "ğŸ“Œ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯",
        reply_to_message_id=message.id
    )
# ===== ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± ØªØ§Ø¨Ø¹ process_zip_files =====
async def process_zip_files(user_id, zip_name, chat_id, message_id):
    processing_msg = None
    temp_downloaded_files = []
    
    try:
        processing_msg = await app.send_message(chat_id, "â³ **Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ...**\n\nğŸŒ€ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯", parse_mode=enums.ParseMode.MARKDOWN)
        zip_password = user_states.get(f"{user_id}_password")
        
        zip_progress_task = asyncio.create_task(progress_tracker.update_zip_progress())
        
        total_files = len(user_files[user_id])
        file_info_list = []
        
        for i, finfo in enumerate(user_files[user_id], 1):
            file_msg_id = finfo["message_id"]
            
            try:
                file_msg = await app.get_messages(chat_id, file_msg_id)
                if not file_msg:
                    logger.error(f"Message {file_msg_id} not found")
                    continue
                
                file_name = finfo["file_name"]
                file_path = os.path.join(tempfile.gettempdir(), f"zip_bot_{user_id}_{file_name}")
                temp_downloaded_files.append(file_path)
                
                success = await safe_download_media(
                    file_msg,
                    file_path,
                    file_name,
                    i,
                    total_files,
                    processing_msg
                )
                
                if success and os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    file_size = os.path.getsize(file_path)
                    file_info_list.append({
                        'path': file_path,
                        'name': file_name,
                        'size': file_size,
                        'password': finfo["password"] or zip_password
                    })
                    logger.info(f"Downloaded {file_name} ({progress_tracker.format_size(file_size)})")
                else:
                    logger.error(f"Failed to download {file_name}")
                    try:
                        if os.path.exists(file_path):
                            os.remove(file_path)
                    except:
                        pass
                
                await asyncio.sleep(0.5)
                
            except Exception as e:
                logger.error(f"Error processing file {finfo['file_name']}: {e}")
                continue
        
        if not file_info_list:
            await processing_msg.edit_text("âŒ **Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯**\n\nÙ„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯")
            return
        
        await processing_msg.edit_text("ğŸ“¦ **Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§...**\n\nâ³ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯", parse_mode=enums.ParseMode.MARKDOWN)
        
        # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© ÙØ§ÛŒÙ„ ZIP ÙˆØ§Ø­Ø¯ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        final_zip_name = f"{zip_name}.zip"
        zip_path = os.path.join(tempfile.gettempdir(), f"zip_bot_{user_id}_{final_zip_name}")
        
        total_size = sum(f['size'] for f in file_info_list)
        progress_tracker.reset(processing_msg, "ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ", final_zip_name, 1, 1)
        progress_tracker.total = total_size
        
        success = await create_zip_part_advanced(zip_path, file_info_list, zip_password)
        if not success:
            logger.error(f"Failed to create zip file")
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
            except:
                pass
            
            await processing_msg.edit_text("âŒ **Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾**\n\nÙ„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯")
            return
        
        # Ù‚Ø¨Ù„ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯ØŒ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒÙ… ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ùˆ Ø®Ø§Ù„ÛŒ Ù†ÛŒØ³Øª
        if not os.path.exists(zip_path) or os.path.getsize(zip_path) == 0:
            logger.error(f"Zip file is missing or empty: {zip_path}")
            await processing_msg.edit_text("âŒ **ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª**\n\nÙ„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯")
            return
        
        # Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾
        zip_size = os.path.getsize(zip_path)
        await processing_msg.edit_text(
            f"ğŸ“¤ **Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾...**\n\n"
            f"ğŸ“ Ù†Ø§Ù…: `{final_zip_name}`\n"
            f"ğŸ’¾ Ø­Ø¬Ù…: `{progress_tracker.format_size(zip_size)}`\n"
            f"ğŸ”‘ Ø±Ù…Ø²: `{zip_password or 'Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø²'}`\n"
            f"â³ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯...",
            parse_mode=enums.ParseMode.MARKDOWN
        )
        
        progress_tracker.reset(processing_msg, "Ø¢Ù¾Ù„ÙˆØ¯", final_zip_name, 1, 1)
        
        upload_success = await upload_large_file_chunked(
            file_path=zip_path,
            chat_id=chat_id,
            caption=(
                f"ğŸ“¦ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ø´Ø¯Ù‡\n"
                f"ğŸ”‘ Ø±Ù…Ø²: `{zip_password or 'Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø²'}`\n"
                f"ğŸ’¾ Ø­Ø¬Ù…: {progress_tracker.format_size(zip_size)}"
            ),
            reply_to_message_id=message_id,
            progress_callback=progress_tracker.update_upload_progress,
            progress_args=()
        )
        
        # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ ÙÙ‚Ø· Ø¨Ø¹Ø¯ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÙˆÙÙ‚
        if upload_success:
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
                    logger.info(f"Cleaned up zip file: {zip_path}")
            except Exception as e:
                logger.error(f"Error cleaning up zip file {zip_path}: {e}")
        
        # Ø­Ø°Ù ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ÙÙ‚Ø· Ø¨Ø¹Ø¯ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÙˆÙÙ‚
        if upload_success:
            await cleanup_files(temp_downloaded_files)
        else:
            logger.warning("Upload failed, keeping downloaded files for retry")
        
        if upload_success:
            result_text = (
                f"âœ… **Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!**\n\n"
                f"ğŸ“¦ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: `{final_zip_name}`\n"
                f"ğŸ”‘ Ø±Ù…Ø²: `{zip_password or 'Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø²'}`\n"
                f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: `{len(file_info_list)}`\n"
                f"ğŸ’¾ Ø­Ø¬Ù… Ù†Ù‡Ø§ÛŒÛŒ: `{progress_tracker.format_size(zip_size)}`\n\n"
                f"ğŸ“Œ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø­Ø°Ù Ø´Ø¯Ù†Ø¯"
            )
        else:
            result_text = (
                "âŒ **Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾**\n\n"
                "ğŸ“Œ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø¨Ø³ÛŒØ§Ø± Ø²ÛŒØ§Ø¯ Ø¨Ø§Ø´Ø¯\n"
                "ğŸ”„ Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯"
            )
        
        await safe_send_message(
            chat_id,
            result_text,
            reply_to_message_id=message_id,
            parse_mode=enums.ParseMode.MARKDOWN
        )
        
    except FloodWait as e:
        logger.warning(f"â° FloodWait Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²ÛŒÙ¾: {e.value} Ø«Ø§Ù†ÛŒÙ‡")
        
        if processing_msg:
            await processing_msg.edit_text(
                f"â³ **Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯**\n\n"
                f"ğŸ•’ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¹Ø¯ Ø§Ø²: {e.value} Ø«Ø§Ù†ÛŒÙ‡\n"
                f"âœ… Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø®ÙˆØ§Ù‡Ø¯ ÛŒØ§ÙØª",
                parse_mode=enums.ParseMode.MARKDOWN
            )
        
        schedule_task(process_zip_files, e.value + 10, user_id, zip_name, chat_id, message_id)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²ÛŒÙ¾: {e}", exc_info=True)
        if processing_msg:
            await processing_msg.edit_text(
                "âŒ **Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø® Ø¯Ø§Ø¯**\n\n"
                "ğŸ“Œ Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯",
                parse_mode=enums.ParseMode.MARKDOWN
            )
    finally:
        if 'zip_progress_task' in locals():
            zip_progress_task.cancel()
        
        # ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù…Ù„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø­Ø°Ù Ú©Ù†
        if user_id in user_files:
            user_files[user_id] = []
        user_states.pop(user_id, None)
        user_states.pop(f"{user_id}_password", None)
        user_states.pop(f"{user_id}_zipname", None)
        user_states.pop(f"{user_id}_upload_size", None)
        save_user_data()

# ===== Ø­Ø°Ù Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø§ÛŒØ² Ø¢Ù¾Ù„ÙˆØ¯ =====
# Ø¯Ø± ØªØ§Ø¨Ø¹ start_zip_now Ùˆ handle_callback_query Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø§ÛŒØ² Ø¢Ù¾Ù„ÙˆØ¯ Ø±Ø§ Ø­Ø°Ù ÛŒØ§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯

async def start_zip_now(client, message: Message):
    user_id = message.from_user.id
    
    if not is_user_allowed(user_id):
        return
    
    if user_states.get(user_id) != "ready_to_zip":
        await message.reply("âŒ Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ Ù…Ø±Ø§Ø­Ù„ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ú©Ø§Ù…Ù„ Ú©Ù†ÛŒØ¯")
        return
    
    zip_name = user_states.get(f"{user_id}_zipname", f"archive_{int(time.time())}")
    
    # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²ÛŒÙ¾ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (Ø¨Ø¯ÙˆÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø³Ø§ÛŒØ² Ø¢Ù¾Ù„ÙˆØ¯)
    await message.reply(
        f"ğŸ“¦ **Ø¹Ù…Ù„ÛŒØ§Øª Ø²ÛŒÙ¾ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒØ´ÙˆØ¯...**\n\n"
        f"ğŸ“ Ù†Ø§Ù… ÙØ§ÛŒÙ„: `{zip_name}.zip`\n"
        f"â³ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯",
        parse_mode=enums.ParseMode.MARKDOWN
    )
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ØµÙ Ù¾Ø±Ø¯Ø§Ø²Ø´
    add_to_queue(process_zip_files, user_id, zip_name, message.chat.id, message.id)

# Ø¯Ø± ØªØ§Ø¨Ø¹ handle_callback_queryØŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ "size_" Ùˆ "confirm_zip" Ø±Ø§ Ø­Ø°Ù ÛŒØ§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯
async def handle_callback_query(client, callback_query):
    user_id = callback_query.from_user.id
    data = callback_query.data
    
    if not is_user_allowed(user_id):
        await callback_query.answer("Ø¯Ø³ØªØ±Ø³ÛŒ denied!", show_alert=True)
        return
    
    if data == "start_upload":
        await callback_query.answer()
        await safe_send_message(
            user_id,
            "ğŸ“¤ **Ø­Ø§Ù„Øª Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ ÙØ¹Ø§Ù„ Ø´Ø¯**\n\n"
            "ğŸ“ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
            "ğŸ”‘ Ø¨Ø±Ø§ÛŒ Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø² Ú©Ù¾Ø´Ù† `pass=Ø±Ù…Ø²` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
            "ğŸ“Œ Ù¾Ø³ Ø§Ø² Ø§ØªÙ…Ø§Ù… Ø§Ø² /zip Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯",
            parse_mode=enums.ParseMode.MARKDOWN
        )
    
    elif data == "help":
        await callback_query.answer()
        await safe_send_message(
            user_id,
            "ğŸ“– **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø±Ø¨Ø§Øª**\n\n"
            "1. Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø±Ø¨Ø§Øª Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\n"
            "2. Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ: Ø¯Ø± Ú©Ù¾Ø´Ù† Ø§Ø² `pass=Ø±Ù…Ø²` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
            "3. Ø´Ø±ÙˆØ¹ Ø²ÛŒÙ¾: Ù¾Ø³ Ø§Ø² Ø§Ø±Ø³Ø§Ù„ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ØŒ /zip Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯\n"
            "4. ØªÙ†Ø¸ÛŒÙ…Ø§Øª: Ø±Ù…Ø² Ú©Ù„ÛŒ Ùˆ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯\n"
            "5. Ø¯Ø±ÛŒØ§ÙØª: Ø±Ø¨Ø§Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø²ÛŒÙ¾ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\n\n"
            "âš™ï¸ **ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡:**\n"
            "â€¢ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÛŒÚ©Ø¬Ø§ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§\n"
            "â€¢ Ø¢Ù¾Ù„ÙˆØ¯ ØªÚ©Ù‡ ØªÚ©Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯\n"
            "â€¢ Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ AES-256\n"
            "â€¢ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø² Ø®Ø·Ø§\n\n"
            "ğŸ›  Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ: Ø¯Ø± ØµÙˆØ±Øª Ù…Ø´Ú©Ù„ Ø¨Ø§ /cancel Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯",
            parse_mode=enums.ParseMode.MARKDOWN
        )
    
    elif data == "no_password":
        await callback_query.answer("Ø­Ø§Ù„Øª Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø² Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯")
        user_states[user_id] = "waiting_filename"
        user_states[f"{user_id}_password"] = None
        
        suggested_name = f"archive_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        await safe_send_message(
            user_id,
            f"ğŸ“ **Ø­Ø§Ù„Ø§ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯**\n\n"
            f"ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: {suggested_name}\n"
            f"âš ï¸ ØªÙˆØ¬Ù‡: Ù¾Ø³ÙˆÙ†Ø¯ .zip Ø§Ø¶Ø§ÙÙ‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯"
        )
    
    elif data == "cancel_zip":
        await callback_query.answer("Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯")
        await cancel_zip(client, callback_query.message)
    
    await callback_query.message.delete()

def non_command_filter(_, __, message: Message):
    user_id = message.from_user.id
    return (message.text and 
            not message.text.startswith('/') and 
            user_id in user_states and
            user_states.get(user_id) in ["waiting_password", "waiting_filename"])

non_command = filters.create(non_command_filter)

async def process_zip_files(user_id, zip_name, chat_id, message_id):
    processing_msg = None
    temp_downloaded_files = []
    
    try:
        processing_msg = await app.send_message(chat_id, "â³ **Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ...**\n\nğŸŒ€ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯", parse_mode=enums.ParseMode.MARKDOWN)
        zip_password = user_states.get(f"{user_id}_password")
        
        zip_progress_task = asyncio.create_task(progress_tracker.update_zip_progress())
        
        total_files = len(user_files[user_id])
        file_info_list = []
        
        for i, finfo in enumerate(user_files[user_id], 1):
            file_msg_id = finfo["message_id"]
            
            try:
                file_msg = await app.get_messages(chat_id, file_msg_id)
                if not file_msg:
                    logger.error(f"Message {file_msg_id} not found")
                    continue
                
                file_name = finfo["file_name"]
                file_path = os.path.join(tempfile.gettempdir(), f"zip_bot_{user_id}_{file_name}")
                temp_downloaded_files.append(file_path)
                
                success = await safe_download_media(
                    file_msg,
                    file_path,
                    file_name,
                    i,
                    total_files,
                    processing_msg
                )
                
                if success and os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    file_size = os.path.getsize(file_path)
                    file_info_list.append({
                        'path': file_path,
                        'name': file_name,
                        'size': file_size,
                        'password': finfo["password"] or zip_password
                    })
                    logger.info(f"Downloaded {file_name} ({progress_tracker.format_size(file_size)})")
                else:
                    logger.error(f"Failed to download {file_name}")
                    try:
                        if os.path.exists(file_path):
                            os.remove(file_path)
                    except:
                        pass
                
                await asyncio.sleep(0.5)
                
            except Exception as e:
                logger.error(f"Error processing file {finfo['file_name']}: {e}")
                continue
        
        if not file_info_list:
            await processing_msg.edit_text("âŒ **Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø´Ø¯**\n\nÙ„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯")
            return
        
        await processing_msg.edit_text("ğŸ“¦ **Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ 400 Ù…Ú¯Ø§Ø¨Ø§ÛŒØªÛŒ...**\n\nâ³ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯", parse_mode=enums.ParseMode.MARKDOWN)
        
        file_info_list.sort(key=lambda x: x['size'], reverse=True)
        
        parts = []
        current_part = []
        current_size = 0
        
        for file_info in file_info_list:
            file_size = file_info['size']
            
            if file_size > 350 * 1024 * 1024:
                if current_part:
                    parts.append(current_part)
                    current_part = []
                    current_size = 0
                parts.append([file_info])
                logger.info(f"Large file in separate part: {file_info['name']} ({file_size/1024/1024:.1f}MB)")
            else:
                if current_size + file_size > Config.PART_SIZE:
                    if current_part:
                        parts.append(current_part)
                        current_part = []
                        current_size = 0
                
                current_part.append(file_info)
                current_size += file_size
        
        if current_part:
            parts.append(current_part)
        
        num_parts = len(parts)
        logger.info(f"Created {num_parts} parts from {len(file_info_list)} files")
        
        if num_parts == 0:
            await processing_msg.edit_text("âŒ **Ù‡ÛŒÚ† Ù¾Ø§Ø±ØªÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯**\n\nÙ„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯")
            return
        
        successful_parts = 0
        
        for part_index, part_files in enumerate(parts):
            part_number = part_index + 1
            part_zip_name = f"{zip_name}_part{part_number}.zip"
            zip_path = os.path.join(tempfile.gettempdir(), f"zip_bot_{user_id}_{part_zip_name}")
            
            part_password = zip_password
            part_size_mb = sum(f['size'] for f in part_files) / (1024 * 1024)
            
            logger.info(f"Processing part {part_number}/{num_parts}, "
                       f"files: {len(part_files)}, size: {part_size_mb:.1f}MB")
            
            await processing_msg.edit_text(
                f"ğŸ—œï¸ **Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø±Øª {part_number}/{num_parts}**\n\n"
                f"ğŸ“ Ø´Ø§Ù…Ù„ {len(part_files)} ÙØ§ÛŒÙ„\n"
                f"ğŸ’¾ Ø­Ø¬Ù…: {part_size_mb:.1f}MB\n"
                f"â³ Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯...",
                parse_mode=enums.ParseMode.MARKDOWN
            )
            
            total_part_size = sum(f['size'] for f in part_files)
            progress_tracker.reset(processing_msg, "ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ", f"Ù¾Ø§Ø±Øª {part_number}", part_number, num_parts)
            progress_tracker.total = total_part_size
            
            success = await create_zip_part_advanced(zip_path, part_files, part_password)
            if not success:
                logger.error(f"Failed to create zip part {part_number}")
                try:
                    if os.path.exists(zip_path):
                        os.remove(zip_path)
                except:
                    pass
                continue
            
            # Ù‚Ø¨Ù„ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯ØŒ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒÙ… ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ùˆ Ø®Ø§Ù„ÛŒ Ù†ÛŒØ³Øª
            if not os.path.exists(zip_path) or os.path.getsize(zip_path) == 0:
                logger.error(f"Zip file is missing or empty: {zip_path}")
                continue
            
            upload_success = await upload_zip_part(
                zip_path, 
                part_index, 
                num_parts, 
                chat_id, 
                message_id, 
                part_password or "Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø²",
                processing_msg
            )
            
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
                    logger.info(f"Cleaned up zip part: {zip_path}")
            except Exception as e:
                logger.error(f"Error cleaning up zip part {zip_path}: {e}")
            
            if upload_success:
                successful_parts += 1
                logger.info(f"Part {part_number} processed successfully")
            else:
                logger.error(f"Failed to upload part {part_number}")
            
            await asyncio.sleep(1)
        
        await cleanup_files(temp_downloaded_files)
        
        if successful_parts > 0:
            result_text = (
                f"âœ… **Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!**\n\n"
                f"ğŸ“¦ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: `{successful_parts}/{num_parts}`\n"
                f"ğŸ”‘ Ø±Ù…Ø² Ø§ØµÙ„ÛŒ: `{zip_password or 'Ø¨Ø¯ÙˆÙ† Ø±Ù…Ø²'}`\n\n"
                f"ğŸ“Œ **Ù†Ú©Ø§Øª Ù…Ù‡Ù…:**\n"
                f"â€¢ Ø¨Ø±Ø§ÛŒ extract Ù‡Ù…Ù‡ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯\n"
                f"â€¢ Ø§Ø² Ø±Ù…Ø² ÛŒÚ©Ø³Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
                f"â€¢ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø­Ø°Ù Ø´Ø¯Ù†Ø¯"
            )
        else:
            result_text = (
                "âŒ **Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§**\n\n"
                "ğŸ“Œ Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø®Ø±Ø§Ø¨ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯ ÛŒØ§ Ø­Ø¬Ù… Ø¨Ø³ÛŒØ§Ø± Ø²ÛŒØ§Ø¯ Ø¨Ø§Ø´Ø¯\n"
                "ğŸ”„ Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ Ùˆ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯"
            )
        
        await safe_send_message(
            chat_id,
            result_text,
            reply_to_message_id=message_id,
            parse_mode=enums.ParseMode.MARKDOWN
        )
        
    except FloodWait as e:
        logger.warning(f"â° FloodWait Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²ÛŒÙ¾: {e.value} Ø«Ø§Ù†ÛŒÙ‡")
        
        if processing_msg:
            await processing_msg.edit_text(
                f"â³ **Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯**\n\n"
                f"ğŸ•’ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¹Ø¯ Ø§Ø²: {e.value} Ø«Ø§Ù†ÛŒÙ‡\n"
                f"âœ… Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø®ÙˆØ§Ù‡Ø¯ ÛŒØ§ÙØª",
                parse_mode=enums.ParseMode.MARKDOWN
            )
        
        schedule_task(process_zip_files, e.value + 10, user_id, zip_name, chat_id, message_id)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²ÛŒÙ¾: {e}", exc_info=True)
        if processing_msg:
            await processing_msg.edit_text(
                "âŒ **Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø® Ø¯Ø§Ø¯**\n\n"
                "ğŸ“Œ Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯",
                parse_mode=enums.ParseMode.MARKDOWN
            )
    finally:
        if 'zip_progress_task' in locals():
            zip_progress_task.cancel()
        
        await cleanup_files(temp_downloaded_files)
        
        if user_id in user_files:
            user_files[user_id] = []
        user_states.pop(user_id, None)
        user_states.pop(f"{user_id}_password", None)
        user_states.pop(f"{user_id}_zipname", None)
        save_user_data()

async def run_bot():
    global app
    logger.info("ğŸš€ Starting advanced zip/upload bot...")
    
    load_user_data()
    
    app = Client(
        "user_bot",
        api_id=Config.API_ID,
        api_hash=Config.API_HASH,
        session_string=Config.SESSION_STRING,
        in_memory=True
    )
    
    app.on_message(filters.command("start"))(start)
    app.on_message(filters.document | filters.video | filters.audio)(handle_file)
    app.on_message(filters.command("zip"))(start_zip)
    app.on_message(filters.command("zipnow"))(start_zip_now)
    app.on_message(filters.command("done"))(handle_done_command)
    app.on_message(filters.command("cancel"))(cancel_zip)
    app.on_message(filters.text & non_command)(process_zip)
    app.on_callback_query()(handle_callback_query)
    
    asyncio.create_task(process_scheduled_tasks())
    asyncio.create_task(process_task_queue())
    
    await app.start()
    logger.info("âœ… Bot started successfully with advanced features!")
    
    async def periodic_save():
        while True:
            await asyncio.sleep(300)
            save_user_data()
            logger.info("ğŸ’¾ User data saved periodically")
    
    asyncio.create_task(periodic_save())
    
    await asyncio.Event().wait()

if __name__ == "__main__":
    web_app = Flask(__name__)
    
    @web_app.route('/')
    def home():
        return "ğŸ¤– Advanced Zip/Upload Bot is Running", 200
    
    @web_app.route('/health')
    def health_check():
        return {
            "status": "healthy",
            "queue_size": len(task_queue),
            "scheduled_tasks": len(scheduled_tasks),
            "users_with_files": len(user_files),
            "timestamp": time.time()
        }, 200
    
    @web_app.route('/stats')
    def stats():
        total_files = sum(len(files) for files in user_files.values())
        total_size = sum(f["file_size"] for files in user_files.values() for f in files)
        return {
            "total_users": len(user_files),
            "total_files": total_files,
            "total_size": total_size,
            "formatted_size": progress_tracker.format_size(total_size)
        }, 200
    
    def start_bot():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(run_bot())
        except Exception as e:
            logger.error(f"Bot error: {e}")
        finally:
            loop.close()
            zip_executor.shutdown(wait=True)
    
    bot_thread = threading.Thread(target=start_bot, daemon=True)
    bot_thread.start()
    
    port = int(os.environ.get("PORT", 10000))
    logger.info(f"ğŸŒ Starting Flask web server on port {port}...")
    
    def run_web_app():
        web_app.run(host="0.0.0.0", port=port, debug=False, use_reloader=False)
    
    web_thread = threading.Thread(target=run_web_app, daemon=True)
    web_thread.start()
    
    try:
        bot_thread.join()
        web_thread.join()
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ Bot stopped by user")
        save_user_data()
        zip_executor.shutdown(wait=False)
        sys.exit(0)
